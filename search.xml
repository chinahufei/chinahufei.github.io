<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Spark社区博客合集</title>
      <link href="/2020/01/06/Spark%E7%A4%BE%E5%8C%BA%E5%8D%9A%E5%AE%A2%E5%90%88%E9%9B%86/"/>
      <url>/2020/01/06/Spark%E7%A4%BE%E5%8C%BA%E5%8D%9A%E5%AE%A2%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark社区博客合集"><a href="#Spark社区博客合集" class="headerlink" title="Spark社区博客合集"></a>Spark社区博客合集</h1><ul><li><ol><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483881&idx=1&sn=b2e826162de4d94dcf0119556e2d7f50&chksm=cef37c68f984f57e1c672a72e90bdd09a2a9cf2239a9d472fe9b9caebcc381e8a47c2b17b9f8&scene=21#wechat_redirect" target="_blank" rel="noopener" title="浅谈 Spark 的多语言支持">浅谈 Spark 的多语言支持</a></li></ol></li><li><ol start="2"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483911&idx=1&sn=454c75b8a75a2cc539ede95f8d6e816d&chksm=cef37f86f984f6909696851320b3ecbc9fcf1acf41d49719ae93ba992dea514eb32dad0e0f63&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Apache Spark3.0什么样？一文读懂Apache Spark最新技术发展与展望">Apache Spark3.0什么样？一文读懂Apache Spark最新技术发展与展望</a></li></ol></li><li><ol start="3"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483668&idx=1&sn=cb7517ba0ef98654ab0b1cf2ab484b8e&chksm=cef37c95f984f583df8a4550e9885800f444325e82ce249257f353ad1c7e650032ef2791653f&scene=21#wechat_redirect" target="_blank" rel="noopener" title="基于Spark SQL实现对HDFS操作的实时监控报警">基于Spark SQL实现对HDFS操作的实时监控报警</a></li></ol></li><li><ol start="4"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483689&idx=1&sn=c706af287c3f729bfb00c7b143021fbd&chksm=cef37ca8f984f5be39eb2bcae63b16d4c826227a34a2af4d6ed295f67a21796f9588bedb8912&scene=21#wechat_redirect" target="_blank" rel="noopener" title="通过Spark SQL实时归档SLS数据">通过Spark SQL实时归档SLS数据</a></li></ol></li><li><ol start="5"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483704&idx=1&sn=76e442e7f0a03c85abf2cc0ecb73b8e6&chksm=cef37cb9f984f5afd0aff253dcd1cb33ec48a1a610add176ffa236a4f8050bbdb9414333ccd5&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用Spark SQL进行流式机器学习计算（上）">使用Spark SQL进行流式机器学习计算（上）</a></li></ol></li><li><ol start="6"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483715&idx=1&sn=4f1b94a5d4b45e51f45b5ea04e1b5754&chksm=cef37cc2f984f5d434752b8c74c9657d46488fbefff3e5dc1868d44832d38b29413bcdfc4843&scene=21#wechat_redirect" target="_blank" rel="noopener" title="通过WebUI查看Structured Streaming作业统计信息">通过WebUI查看Structured Streaming作业统计信息</a></li></ol></li><li><ol start="7"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484099&idx=1&sn=90d9144115b857ff27cb2fa09f1cd232&chksm=cef37f42f984f65493868fee2a09f571a8215bd6f0bf1efd06b0cf8c443308d392f1b86a74f7&scene=21#wechat_redirect" target="_blank" rel="noopener" title="现代流式计算的基石：Google DataFlow">现代流式计算的基石：Google DataFlow</a></li></ol></li><li><ol start="8"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483675&idx=1&sn=b09c5123162a046268a6657d9ca7b42c&chksm=cef37c9af984f58c0581aaf1fa11c58d0e402b9716dd3c463d46176424c5678cdd93a92110de&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark Streaming 框架在 5G 中的应用">Spark Streaming 框架在 5G 中的应用</a></li></ol></li><li><ol start="9"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484033&idx=1&sn=1d923e1be4dc45e5c9da75b79dffd8b4&chksm=cef37f00f984f61602812facac0b24170963a947588a3dc4aa798d3f2600b912de5ba9847868&scene=21#wechat_redirect" target="_blank" rel="noopener" title="是时候放弃 Spark Streaming, 转向 Structured Streaming 了">是时候放弃 Spark Streaming, 转向 Structured Streaming 了</a></li></ol></li><li><ol start="10"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483761&idx=1&sn=db22e6a7378fe8ac0d40864816fa424e&chksm=cef37cf0f984f5e6f31ff140ca7de7b82f2a30cbae198eb7bc9138e4ef2e19ba344d83d5fa12&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用Spark Streaming SQL基于时间窗口进行数据统计">使用Spark Streaming SQL基于时间窗口进行数据统计</a></li></ol></li></ul><hr><ul><li><ol start="11"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484390&idx=1&sn=8abd8c464fac305f50962d58331ae7d7&chksm=cef37e67f984f771ea3ef605f85a96a3b37653d55288b6a79aa01b43441c38ef3c8e3cbe9a78&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark-StructuredStreaming checkpointLocation分析、优化耗时">Spark-StructuredStreaming checkpointLocation分析、优化耗时</a></li></ol></li><li><ol start="12"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484253&idx=1&sn=9d3fac47921def314049ab5644e2f785&chksm=cef37edcf984f7ca034a1a9074d752afa9b62756d3dbedb0c2bdb21f2f026e7a5e005ec1db03&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用Spark Streaming SQL进行PV/UV统计">使用Spark Streaming SQL进行PV/UV统计</a></li></ol></li><li><ol start="13"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484515&idx=1&sn=eee77f3d2d1a20ed77c3edd3639ad275&chksm=cef379e2f984f0f498277fcc9858c715deef84f39f5b31b01325a9aef73e89568eb222887f13&scene=21#wechat_redirect" target="_blank" rel="noopener" title="通过Spark Streaming作业处理Kafka数据">通过Spark Streaming作业处理Kafka数据</a></li></ol></li><li><ol start="14"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484537&idx=1&sn=e0319f5942e6768cf17e0e21ad669ead&chksm=cef379f8f984f0eea9a5137be8460ea39d6e77f5dcacc81e60ac7c974e55efabf5f3eb057b04&scene=21#wechat_redirect" target="_blank" rel="noopener" title="通过Kafka Connect进行数据迁移">通过Kafka Connect进行数据迁移</a></li></ol></li><li><ol start="15"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483695&idx=1&sn=4e66800691d381c2fe26d9574b470207&chksm=cef37caef984f5b8f02201ffb3522557c44991bc20b6b868e1b82355623bf3a2dc8c009196ca&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark内置图像数据源初探">Spark内置图像数据源初探</a></li></ol></li><li><ol start="16"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483744&idx=1&sn=d4a5ebefd352762d6bc4cbd60841a9aa&chksm=cef37ce1f984f5f785ad59165446e2164e4993d564b757fb18375ab8cfa0e9f9a51ca9ee9730&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】Spark-Alchemy：HyperLogLog的使用介绍">【译】Spark-Alchemy：HyperLogLog的使用介绍</a></li></ol></li><li><ol start="17"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483754&idx=1&sn=681659dc5e273bde4ea2cedb97753d76&chksm=cef37cebf984f5fdbd636fc296e7b6be6363881305e629ecb8078b70643cd646ea1d0f38b393&scene=21#wechat_redirect" target="_blank" rel="noopener" title="EMR Spark Runtime Filter性能优化">EMR Spark Runtime Filter性能优化</a></li></ol></li><li><ol start="18"><li><a href="http://baidu.com" target="_blank" rel="noopener" title="EMR Spark Relational Cache如何支持雪花模型中的关联匹配">EMR Spark Relational Cache如何支持雪花模型中的关联匹配</a></li></ol></li><li><ol start="19"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483662&idx=1&sn=de1f7670d3a502b18db675c1047fa057&chksm=cef37c8ff984f59984e52713b5781857ddbb44bdb1a266e724ed661ca859616e554aafc76ebc&scene=21#wechat_redirect" target="_blank" rel="noopener" title="EMR Spark Relational Cache的执行计划重写">EMR Spark Relational Cache的执行计划重写</a></li></ol></li><li><ol start="20"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483722&idx=1&sn=bda51fb092e1ccdd4a8bfc9f8fd5e046&chksm=cef37ccbf984f5ddac3d8ba638abdcd315c8c617ab46cb9861172883597cd41ea03eebac6d2b&scene=21#wechat_redirect" target="_blank" rel="noopener" title="EMR Spark Relational Cache 利用数据预组织加速查询">EMR Spark Relational Cache 利用数据预组织加速查询</a></li></ol></li></ul><hr><ul><li><ol start="21"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483815&idx=1&sn=d58da251890d9ed6cf914cdee478ad00&chksm=cef37c26f984f5302abff1ae5ae01ae947b6105988f74a586134b427c76431d3a63d77f20e4a&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用Relational Cache加速EMR Spark数据分析">使用Relational Cache加速EMR Spark数据分析</a></li></ol></li><li><ol start="22"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483821&idx=1&sn=975cfdca7315202d3ca9af717edd6d03&chksm=cef37c2cf984f53a560bf6050879d18641267117702dddaab62cc2510150d4118a37366088b3&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用EMR Spark Relational Cache跨集群同步数据">使用EMR Spark Relational Cache跨集群同步数据</a></li></ol></li><li><ol start="23"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484191&idx=1&sn=079fd10f5cf2a67059dffbb64fe269ba&chksm=cef37e9ef984f7883572869eb7b4096295d52fb7ceac092f3fb692292bec293dae7fbc1b426d&scene=21#wechat_redirect" target="_blank" rel="noopener" title="2019杭州云栖大会回顾之Spark Relational Cache实现亚秒级响应的交互式分析">2019杭州云栖大会回顾之Spark Relational Cache实现亚秒级响应的交互式分析</a></li></ol></li><li><ol start="24"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483766&idx=1&sn=0c11d9c3c56193837dbb683ddf41168f&chksm=cef37cf7f984f5e19a567ba1a86199ae0780a33448e3711f2a3a08beee5d24224f3d9a69cffa&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】数据湖正在成为新的数据仓库">【译】数据湖正在成为新的数据仓库</a></li></ol></li><li><ol start="25"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484135&idx=1&sn=8f2f44846a9e2c4e99b9e51cb9456b1f&chksm=cef37f66f984f670875bfe17fce1e3ca8f8255a09e3a0c9bbd102e8231646a0df1cfcdb4efb2&scene=21#wechat_redirect" target="_blank" rel="noopener" title="深入剖析 Delta Lake：详解事务日志">深入剖析 Delta Lake：详解事务日志</a></li></ol></li><li><ol start="26"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484422&idx=1&sn=04c6d12dbba9f7a3a54cdd040a55e1e9&chksm=cef37987f984f091e2506235eeba2e4f846845c2dda8e0e59f3d1733588b2d8dac727c8b5809&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Delta元数据解析">Delta元数据解析</a></li></ol></li><li><ol start="27"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484289&idx=1&sn=c0fba9596c7d92b30efffdf602d81c41&chksm=cef37e00f984f7164c83530a361caca2d80ddf98cd4be5dbfc0de7c0bc99b5808acbab5d73d1&scene=21#wechat_redirect" target="_blank" rel="noopener" title="开源生态的新发展：Apache Spark 3.0、Koala和Delta Lake">开源生态的新发展：Apache Spark 3.0、Koala和Delta Lake</a></li></ol></li><li><ol start="28"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484239&idx=1&sn=e829e3c4ec5b153512e00f501f7897cd&chksm=cef37ecef984f7d83a76d8d2e839d8f13a0962bd3082f1a43e869034362c567bdfb907bd9554&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】Delta Lake 0.4.0 新特性演示：使用 Python API 就地转换与处理 Delta Lake 表">【译】Delta Lake 0.4.0 新特性演示：使用 Python API 就地转换与处理 Delta Lake 表</a></li></ol></li><li><ol start="29"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483772&idx=1&sn=3df58d14be76f5e6a5c3be347a6b0c0f&chksm=cef37cfdf984f5eba135fa1803110621524980ce262f6bcb7c845b2d578638f2ef2fa3e2d527&scene=21#wechat_redirect" target="_blank" rel="noopener" title="漫谈分布式计算框架">漫谈分布式计算框架</a></li></ol></li><li><ol start="30"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484089&idx=1&sn=33bc88b4c742a5db2457a546abc242fc&chksm=cef37f38f984f62ed6097cc51dacd79853c791de59e1b15530fd6e48d7b2f131ffae59399cec&scene=21#wechat_redirect" target="_blank" rel="noopener" title="分布式快照算法: Chandy-Lamport">分布式快照算法: Chandy-Lamport</a></li></ol></li></ul><hr><ul><li><ol start="31"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484386&idx=1&sn=8f3b221eac11e7ffd5b17c0f763e3f53&chksm=cef37e63f984f77596a930607c2abd4e904cfd8ebaca7132a3a4ad5918ffa6e67210a279c8ed&scene=21#wechat_redirect" target="_blank" rel="noopener" title="海量小文件的的根源">海量小文件的的根源</a></li></ol></li><li><ol start="32"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484436&idx=1&sn=8d98e389861f17f9aadaede61a7317de&chksm=cef37995f984f0831ca93c8220dca5bfa896f5a60f1313220deb56e14c33a049241619adcac1&scene=21#wechat_redirect" target="_blank" rel="noopener" title="是时候改变你数仓的增量同步方案了">是时候改变你数仓的增量同步方案了</a></li></ol></li><li><ol start="33"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483782&idx=1&sn=07208d07cc965deb9f1cea3f8835e12a&chksm=cef37c07f984f51155fbbb6b59f265b9a14bf728e9e79c84f715ad165c3f578a357b7adb7269&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】Spark NLP使用入门">【译】Spark NLP使用入门</a></li></ol></li><li><ol start="34"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483794&idx=1&sn=47a825732ac760727a74820c3f699d70&chksm=cef37c13f984f505359b507edbed95bf4910048ac2693f1b1c3c7d16c243aabe7b5b5aaaea72&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】使用Spark SQL 运行大规模基因组工作流">【译】使用Spark SQL 运行大规模基因组工作流</a></li></ol></li><li><ol start="35"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483808&idx=1&sn=753003e5b7935abfb4ee297a20ff15d3&chksm=cef37c21f984f53735c14836f5c081a4a3a0bbb8c630476aa193b281aa0311ee78c91bdaf5bd&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】用SQL统一所有：一种有效的、语法惯用的流和表管理方法">【译】用SQL统一所有：一种有效的、语法惯用的流和表管理方法</a></li></ol></li><li><ol start="36"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483828&idx=1&sn=509db7520dd7f4de308e73e3ee696a03&chksm=cef37c35f984f523383a369725a8e047e0d0f7f9c7eb6306766fab92c0451c2f0f427950519b&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用Apache Arrow助力PySpark数据处理">使用Apache Arrow助力PySpark数据处理</a></li></ol></li><li><ol start="37"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483849&idx=1&sn=45a14c21cb7eba6b962761844495207c&chksm=cef37c48f984f55ee32ac526fade0b80804869b9fa891c9bbd4af295543d981563c50cea6a2a&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark on Kubernetes原生支持浅析">Spark on Kubernetes原生支持浅析</a></li></ol></li><li><ol start="38"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483989&idx=1&sn=86cdf3234cdf4975f33ab2de2472f1af&chksm=cef37fd4f984f6c2b5ee059bd859658182f70b5653f15accec53e780d8b7ef6eb3a760187dd3&scene=21#wechat_redirect" target="_blank" rel="noopener" title="列式存储系列（一）C-Store">列式存储系列（一）C-Store</a></li></ol></li><li><ol start="39"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484050&idx=1&sn=c2a62ea715e40d69d8e24a3c93a3ee2f&chksm=cef37f13f984f60599e308323902fd74bbfb60f8a0d2ae51f7f9e349ab509061465f48613509&scene=21#wechat_redirect" target="_blank" rel="noopener" title="列式存储系列（二）: Vertica">列式存储系列（二）: Vertica</a></li></ol></li><li><ol start="40"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483916&idx=1&sn=5edb12e5c4c4ca85338a17a1d87fae19&chksm=cef37f8df984f69bc249700d592f55a64e3e3aa6328fe8bec7cbbab10f6de15c68312a6b8bcc&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark on Kubernetes 的现状与挑战">Spark on Kubernetes 的现状与挑战</a></li></ol></li></ul><hr><ul><li><ol start="41"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483855&idx=1&sn=af287d5cd33baab52b947d69d97af72a&chksm=cef37c4ef984f5580b8602b47413f7a80e684c80e84c14b389c1cbf33e9c3a2c3198c23d5f8f&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Koalas：让 pandas 轻松切换 Apache Spark">Koalas：让 pandas 轻松切换 Apache Spark</a></li></ol></li><li><ol start="42"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483976&idx=1&sn=aa39393aecdafdd1453fb632c938b895&chksm=cef37fc9f984f6dffe6fd1f2451226918242a01ae7d2e307de0bea71bfbcfab4875cfc577596&scene=21#wechat_redirect" target="_blank" rel="noopener" title="使用spark-redis组件访问云数据库Redis">使用spark-redis组件访问云数据库Redis</a></li></ol></li><li><ol start="43"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484065&idx=1&sn=44f5e82b7505b85d9326ca80f8e876ce&chksm=cef37f20f984f6362a7d839d50bbe1a475693ec197d92b7e1a9c4572e44b03d804953efd364f&scene=21#wechat_redirect" target="_blank" rel="noopener" title="玩转阿里云EMR三部曲-高级篇 交互式查询及统一数据源">玩转阿里云EMR三部曲-高级篇 交互式查询及统一数据源</a></li></ol></li><li><ol start="44"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484079&idx=1&sn=dc83ea5ef255a5f6e7042b276ad26572&chksm=cef37f2ef984f63896367dff68264abfe296c0782b52b8ea84c12582c5ea9d1f41f2a19600d9&scene=21#wechat_redirect" target="_blank" rel="noopener" title="HIVE优化浅谈">HIVE优化浅谈</a></li></ol></li><li><ol start="45"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247483971&idx=1&sn=38cbea5fac93d6c63145de1dba8379d8&chksm=cef37fc2f984f6d41809bfa99c7f624adea2f67f7f72b6778f3d0f7cec1886944a5aa48b4e2c&scene=21#wechat_redirect" target="_blank" rel="noopener" title="HIVE TopN shuffle 原理">HIVE TopN shuffle 原理</a></li></ol></li><li><ol start="46"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484125&idx=1&sn=6ae156fd32cd99b99f3e2478baf29bf0&chksm=cef37f5cf984f64a554ce6ad9a2f764f2be52efd12b12a9c13f907e482550ef6bbe7a92495c3&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Kerberos使用OpenLDAP作为backend">Kerberos使用OpenLDAP作为backend</a></li></ol></li><li><ol start="47"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484140&idx=1&sn=b95fbe4b5d129e1db0a56bbdb576a19b&chksm=cef37f6df984f67b83ac3982b984a267698b0e98332f30887bf76b8fc729650fab86e0481af3&scene=21#wechat_redirect" target="_blank" rel="noopener" title="在 Apache Spark 中利用 HyperLogLog 函数实现高级分析">在 Apache Spark 中利用 HyperLogLog 函数实现高级分析</a></li></ol></li><li><ol start="48"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484145&idx=1&sn=3556e991ee6a78e6cf7ccede81031c8b&chksm=cef37f70f984f666b9c53bed558ba41154839d3cd93247d568bb0f4b2f9ed6b458138efa2664&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】Hadoop发生了什么？我们该如何做？">【译】Hadoop发生了什么？我们该如何做？</a></li></ol></li><li><ol start="49"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484159&idx=1&sn=640e5c5d0740ba6383eaec9279dc9391&chksm=cef37f7ef984f668d317d4a5616adcf288b8982832c9ca0d4d46f2ac6c1eb09c001642f2a04e&scene=21#wechat_redirect" target="_blank" rel="noopener" title="实时 OLAP 系统 Druid">实时 OLAP 系统 Druid</a></li></ol></li><li><ol start="50"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484371&idx=1&sn=f03697a4d2e4c3a34de458338b529a0a&chksm=cef37e52f984f744f8555f630f16772312bcbed08b77b329d5d1eeec7847a6ecc8aec2d64c07&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark Operator浅析">Spark Operator浅析</a></li></ol></li></ul><hr><ul><li><ol start="51"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484381&idx=1&sn=43faa5a979811eb520fac6f3bf1ece91&chksm=cef37e5cf984f74ad4cfbab984fc294108e4aa32c73dc6f15bb1af2e4ae98f995018b727ad60&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark Codegen浅析">Spark Codegen浅析</a></li></ol></li><li><ol start="52"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484475&idx=1&sn=ed1e96a9588276ca19c8cfe4418d2ed9&chksm=cef379baf984f0acbeb0ae1449a8c99bb439dad677624a5c77bd94c76b468e0fd5fdf723d837&scene=21#wechat_redirect" target="_blank" rel="noopener" title="深入分析Spark UDF的性能">深入分析Spark UDF的性能</a></li></ol></li><li><ol start="53"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484485&idx=1&sn=89751ffb18da71e67fd6bafd1daf5c81&chksm=cef379c4f984f0d29ad2a5ee7f542d3e7b207a91ed2e830574406081abab426e8f822f3b3bd4&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Spark整合Ray思路漫谈">Spark整合Ray思路漫谈</a></li></ol></li><li><ol start="54"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484460&idx=1&sn=91d559469766528d1dbb92b9b839a03d&chksm=cef379adf984f0bbda673769f54680da311cc04cbbb0f7abec647bd2abcb062068f1331966fc&scene=21#wechat_redirect" target="_blank" rel="noopener" title="Tablestore结合Spark的流批一体SQL实战">Tablestore结合Spark的流批一体SQL实战</a></li></ol></li><li><ol start="55"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484315&idx=1&sn=ff545922c7e6fe1d0d82d1d1c6259e10&chksm=cef37e1af984f70c966742aaac1ef8fe75684068c966323513c27f4f3e9e3d3bb2803197235d&scene=21#wechat_redirect" target="_blank" rel="noopener" title="助力云上开源生态 - 阿里云开源大数据平台的发展">助力云上开源生态 - 阿里云开源大数据平台的发展</a></li></ol></li><li><ol start="56"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484198&idx=1&sn=9f164807c71aa97a6a7aaf09c2096978&chksm=cef37ea7f984f7b1b4dddeef3ce29428e20d11f5510582120de547e13de97ebdefa6a11fcac9&scene=21#wechat_redirect" target="_blank" rel="noopener" title="JindoFS概述：云原生的大数据计算存储分离方案">JindoFS概述：云原生的大数据计算存储分离方案</a></li></ol></li><li><ol start="57"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484219&idx=1&sn=d04e016a8ddfba3e48d6d8697fb4498e&chksm=cef37ebaf984f7ac2db3c7308bc345bf9fc61f1c9e930747c368187944fe5f76afa9b0ec3c6c&scene=21#wechat_redirect" target="_blank" rel="noopener" title="JindoFS解析 - 云上大数据高性能数据湖存储方案">JindoFS解析 - 云上大数据高性能数据湖存储方案</a></li></ol></li><li><ol start="58"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484341&idx=1&sn=0eba127af5ad2cbfbf4b1aa7b8f43743&chksm=cef37e34f984f72294d73170186961d378d83ecc2ff34c0311d738e0098fe8621aa5bfac0e60&scene=21#wechat_redirect" target="_blank" rel="noopener" title="EMR打造高效云原生数据分析引擎">EMR 打造高效云原生数据分析引擎</a></li></ol></li><li><ol start="59"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484259&idx=1&sn=479254c306d4ed3a9f3a91d6e38f5676&chksm=cef37ee2f984f7f438a5c04e09dabc89935952cde4a4deac454faa5464b20a8f8de35966304a&scene=21#wechat_redirect" target="_blank" rel="noopener" title="5分钟迅速搭建云上Lambda大数据分析架构">5分钟迅速搭建云上Lambda大数据分析架构</a></li></ol></li><li><ol start="60"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484294&idx=1&sn=002b8f59d7af075f545f696ca0495452&chksm=cef37e07f984f711c7a014aba75facd49ff79b39f19b9c772ca0d90f4eb78dbb4e1da63f13d2&scene=21#wechat_redirect" target="_blank" rel="noopener" title="如何在Spark中实现Count Distinct重聚合">如何在Spark中实现Count Distinct重聚合</a></li></ol></li><li><ol start="61"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484320&idx=1&sn=6f367d84c63082cec63f985fb0076d1a&chksm=cef37e21f984f737a3aa19a38079cc4075c3ae344db219f1c8469c758e022d2d0138cbf6344a&scene=21#wechat_redirect" target="_blank" rel="noopener" title="基于Spark和TensorFlow 的机器学习实践">基于 Spark 和 TensorFlow 的机器学习实践</a></li></ol></li><li><ol start="62"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484470&idx=1&sn=0c22ce21702fb737e8a79a56c38b2e5f&chksm=cef379b7f984f0a1100e45bc8b20519fb328cdf01b6cc8d1c004889546d6c5d6111ae29b3c6f&scene=21#wechat_redirect" target="_blank" rel="noopener" title="如何用Apache Spark和LightGBM构建机器学习模型来预测信用卡欺诈">如何用Apache Spark和LightGBM构建机器学习模型来预测信用卡欺诈</a></li></ol></li><li><ol start="63"><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjI0NjUxMA==&mid=2247484494&idx=1&sn=da104a0df150c62b76576309f735b792&chksm=cef379cff984f0d99647708fe6be8d2a82c4c36b18837c43cbe00d1189b42a7e84e8367c698d&scene=21#wechat_redirect" target="_blank" rel="noopener" title="【译】Apache Spark 数据建模之时间维度（一）">【译】Apache Spark 数据建模之时间维度（一）</a></li></ol></li></ul><h1 id="Spark社区历次直播视频"><a href="#Spark社区历次直播视频" class="headerlink" title="Spark社区历次直播视频"></a>Spark社区历次直播视频</h1><h3 id="12月11日-【实时数仓建设以及典型场景应用】"><a href="#12月11日-【实时数仓建设以及典型场景应用】" class="headerlink" title="12月11日 【实时数仓建设以及典型场景应用】"></a>12月11日 <a href="https://developer.aliyun.com/live/1758?spm=a2c6h.12873639.0.0.3cb3219eS0rUBN" target="_blank" rel="noopener">【实时数仓建设以及典型场景应用】</a></h3><blockquote><p>本次分享会介绍实时数仓的思路以及一些实践，包括SparkStreaming SQL引擎，以及对Delta/Kudu/Druid/阿里云多种存储组件的深度整合；同时会在这个基础上介绍一些典型案例应用</p></blockquote><h3 id="12月5日-【是时候改变你数仓的增量同步方案了-】"><a href="#12月5日-【是时候改变你数仓的增量同步方案了-】" class="headerlink" title="12月5日 【是时候改变你数仓的增量同步方案了 】"></a>12月5日 <a href="https://developer.aliyun.com/live/1758?spm=a2c6h.12873639.0.0.3cb3219enHW37w" target="_blank" rel="noopener">【是时候改变你数仓的增量同步方案了 】</a></h3><blockquote><p>本次分享会介绍实时数仓的思路以及一些实践，包括SparkStreaming SQL引擎，以及对Delta/Kudu/Druid/阿里云多种存储组件的深度整合；同时会在这个基础上介绍一些典型案例应用</p></blockquote><h3 id="11月28日-【Tablestore结合Spark的云上流批一体大数据架构-】"><a href="#11月28日-【Tablestore结合Spark的云上流批一体大数据架构-】" class="headerlink" title="11月28日 【Tablestore结合Spark的云上流批一体大数据架构 】"></a>11月28日 <a href="https://developer.aliyun.com/live/1716?spm=a2c6h.12873639.0.0.3cb3219enHW37w" target="_blank" rel="noopener">【Tablestore结合Spark的云上流批一体大数据架构 】</a></h3><blockquote><p>传统Lambda架构组件多运维复杂，如何使用一套存储和一套计算来实现流批架构充分享受技术红利？以Delta Lake为代表的新型数据湖方案越来越流行，传统的Lambda架构如何向数据湖架构进行扩展？以及结构化数据结合Delta Lake的最佳解决方案是什么。本次分享将会结合理论讲解和实际场景为您一一解答。</p></blockquote><h3 id="11月16日【阿里云大数据-AI技术沙龙上海站】"><a href="#11月16日【阿里云大数据-AI技术沙龙上海站】" class="headerlink" title="11月16日【阿里云大数据+AI技术沙龙上海站】"></a>11月16日【阿里云大数据+AI技术沙龙上海站】</h3><ul><li><a href="https://developer.aliyun.com/live/1712?spm=a2c6h.12873581.0.0.270f1566XWpLUS&groupCode=apachespark" target="_blank" rel="noopener">基于 Spark 打造高效云原生数据分析引擎</a><blockquote><p>由阿里巴巴 EMR 团队提交的 TPC-DS 成绩在九月份的榜单中取得了排名第一的成绩。这个成绩背后离不开 EMR 团队对 Spark 执行引擎持续不断的优化。<br>本次分享将选取一些有代表性的优化点，深入到技术细节做详细介绍，包括但不限于动态过滤、CBO增强、TopK排序等等。</p></blockquote></li><li><a href="https://developer.aliyun.com/live/1713?spm=a2c6h.12873581.0.0.270f1566XWpLUS&groupCode=apachespark" target="_blank" rel="noopener">使用分布式自动机器学习进行时间序列分析</a><blockquote><p>对于时间序列预测搭建机器学习应用的过程非常繁琐且需要大量经验。为了提供一个简单易用的时间序列预测工具，我们将自动机器学习应用于时间序列预测，将特征生成，模型选择和超参数调优等过程实现自动化。我们的工具基于Ray（UC Berkeley RISELab开源的针对高级AI 应用的分布式框架，并作为Analytics zoo（由intel开源的统一的大数据分析和人工智能平台）的一部分功能提供给用户。</p></blockquote></li><li><a href="https://developer.aliyun.com/live/1714?spm=a2c6h.12873581.0.0.270f1566XWpLUS&groupCode=apachespark" target="_blank" rel="noopener">云上大数据的存储方案设计和选择</a><blockquote><p>上云拐点已来，开源大数据上云是业界共识。如何满足在云上低成本存储海量数据的同时又实现高效率弹性计算的潜在需求？放眼业界，都有哪些成熟存储方案和选择？各自适用的存储和计算场景是什么？背后的技术关键和考虑因素都有哪些？欢迎大数据技术爱好者面对面交流和探讨！</p></blockquote></li><li><a href="https://developer.aliyun.com/live/1715?spm=a2c6h.12873581.0.0.270f1566XWpLUS&groupCode=apachespark" target="_blank" rel="noopener">从Python 到Java ，Pyboot加速大数据和AI的融合</a><blockquote><p>Python 代表机器学习生态，而以 Hadoop/Spark 为核心的开源大数据则以 Java 为主。前者拥有数不清的算法库和程序，后者承载着海量数据和大量的企业应用。除了 SQL 这个标准方式和各种五花八门的协议接口，还有没有更高效的一手数据通道，将两个生态对接起来，乃至深度融合？Pyboot 是我们在这个方向上的探索。有兴趣的同学欢迎现场观摩演示和技术交流。</p></blockquote></li></ul><h3 id="11月14日-【-Spark-on-Kubernetes-amp-YARN】"><a href="#11月14日-【-Spark-on-Kubernetes-amp-YARN】" class="headerlink" title="11月14日 【 Spark on Kubernetes &amp; YARN】"></a>11月14日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41115" target="_blank" rel="noopener">【 Spark on Kubernetes &amp; YARN】</a></h3><blockquote><p>以Kubernetes为代表的云原生技术越来越流行起来，spark是如何跑在Kubernetes之上来享受云原生技术的红利？<br>Spark跑在Kubernetes之上和跑在Hadoop YARN上又有什么区别？以及Kubernetes 和YARN的差异点是什么。</p></blockquote><h3 id="10月17日-【Tablestore-Spark-Streaming-Connector-–-海量结构化数据的实时计算和处理-】"><a href="#10月17日-【Tablestore-Spark-Streaming-Connector-–-海量结构化数据的实时计算和处理-】" class="headerlink" title="10月17日 【Tablestore Spark Streaming Connector – 海量结构化数据的实时计算和处理 】"></a>10月17日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41103" target="_blank" rel="noopener">【Tablestore Spark Streaming Connector – 海量结构化数据的实时计算和处理 】</a></h3><blockquote><p>简介： Tablestore是阿里云自研的云原生结构化大数据存储服务，本议题会详细介绍如何基于Tablestore的CDC技术，将大表内实时数据更新对接Spark Streaming来实现数据的实时计算和处理。最新版本的Connector会随着EMR下个版本的SDK一起开源，场景环节会结合阿里内部的业务介绍用户如何结合Tablestore和Spark来实现实时数据处理。</p></blockquote><h3 id="9月26日-【New-Developments-in-the-Open-Source-Ecosystem-Apache-Spark-3-0-and-Koalas】"><a href="#9月26日-【New-Developments-in-the-Open-Source-Ecosystem-Apache-Spark-3-0-and-Koalas】" class="headerlink" title="9月26日 【New Developments in the Open Source Ecosystem: Apache Spark 3.0 and Koalas】"></a>9月26日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41096" target="_blank" rel="noopener">【New Developments in the Open Source Ecosystem: Apache Spark 3.0 and Koalas】</a></h3><blockquote><p>Apache Spark 3.0 and Koalas的最新进展</p></blockquote><h3 id="9月27日-【助力云上开源生态-阿里云开源大数据平台的发展】"><a href="#9月27日-【助力云上开源生态-阿里云开源大数据平台的发展】" class="headerlink" title="9月27日 【助力云上开源生态 - 阿里云开源大数据平台的发展】"></a>9月27日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41097" target="_blank" rel="noopener">【助力云上开源生态 - 阿里云开源大数据平台的发展】</a></h3><blockquote><p>介绍阿里云上开源生态的发展，阿里云如何更好的支持和融合开源生态，以及未来的发展。</p></blockquote><h3 id="9月27日-【EMR打造高效云原生数据分析引擎】"><a href="#9月27日-【EMR打造高效云原生数据分析引擎】" class="headerlink" title="9月27日 【EMR打造高效云原生数据分析引擎】"></a>9月27日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41098" target="_blank" rel="noopener">【EMR打造高效云原生数据分析引擎】</a></h3><blockquote><p>MR-Jindo 是 EMR 推出的云原生 OLAP 引擎。凭借该引擎，EMR 成为第一个云上 TPC-DS 成绩提交者。经过持续不断地内核优化，目前基于最新 EMR-Jindo 引擎的 TPC-DS 成绩又有了大幅提高，达到了3615071，成本降低到 0.76 CNY。本次分享将介绍 EMR-Jindo 引擎背后的相关技术以及以 EMR-Jindo 为核心的云上大数据架构方案。</p></blockquote><h3 id="9月27日-【云上大数据的一种高性能数据湖存储方案】"><a href="#9月27日-【云上大数据的一种高性能数据湖存储方案】" class="headerlink" title="9月27日 【云上大数据的一种高性能数据湖存储方案】"></a>9月27日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41099" target="_blank" rel="noopener">【云上大数据的一种高性能数据湖存储方案】</a></h3><blockquote><p>大数据上云是业界普遍共识，存储和计算分离的趋势日益显著，如何为云上蓬勃发展的大数据处理和分析引擎提供坚实的存储基础？这个 session 会主要讨论 EMR 技术团队重磅推出的一种新型混合存储解决方案，该方案基于云平台和云存储，面向新的存储硬件和计算发展趋势，为 EMR 弹性计算量身打造，在成本，弹性和性能上追求极佳平衡。技术上是如何实现的？性能如何？覆盖了哪些典型场景，最佳实践是什么？</p></blockquote><h3 id="9月27日-【基于Spark与TensorFlow的机器学习实践】"><a href="#9月27日-【基于Spark与TensorFlow的机器学习实践】" class="headerlink" title="9月27日 【基于Spark与TensorFlow的机器学习实践】"></a>9月27日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41100" target="_blank" rel="noopener">【基于Spark与TensorFlow的机器学习实践】</a></h3><blockquote><p>Apache Spark是目前最火热的计算框架，而TensorFlow是目前最火热的机器学习框架，当他们2个碰撞到一起的时候，也会产生巨大的能量。本议题会介绍EMR和PAI在这个上面的实践。</p></blockquote><h3 id="9月27日-【Spark-Relational-Cache实现亚秒级响应的交互式分析】"><a href="#9月27日-【Spark-Relational-Cache实现亚秒级响应的交互式分析】" class="headerlink" title="9月27日 【Spark Relational Cache实现亚秒级响应的交互式分析】"></a>9月27日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41101" target="_blank" rel="noopener">【Spark Relational Cache实现亚秒级响应的交互式分析】</a></h3><blockquote><p>2019杭州云栖大会大数据生态专场中的分享《Spark Relational Cache实现亚秒级响应的交互式分析》<br>Apache Spark被广泛用于超大规模的数据分析处理，在交互式分析等时间敏感的场景中，超大规模数据量的处理时间可能无法满足用户快速响应的需求。通过数据的预组织和预计算，将频繁访问的数据和计算提前执行并保存在Relational Cache中，优化后续特定模式的查询，可以显著提高查询速度，实现亚秒级的响应。本议题主要介绍Spark Relational Cache的实现原理和使用场景。</p></blockquote><h3 id="9月18日-【阿里巴巴大数据产品最新特性介绍—E-MapReduce】"><a href="#9月18日-【阿里巴巴大数据产品最新特性介绍—E-MapReduce】" class="headerlink" title="9月18日 【阿里巴巴大数据产品最新特性介绍—E-MapReduce】"></a>9月18日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41093" target="_blank" rel="noopener">【阿里巴巴大数据产品最新特性介绍—E-MapReduce】</a></h3><blockquote><p>本次直播将为您介绍E-MapReduce近期发布最新feature，涵盖集群队列管理，弹性伸缩等场景产品的使用。帮助您更快的上手云上开源大数据体系。</p></blockquote><h3 id="8月28日-【Spark-Streaming-SQL流式处理简介】"><a href="#8月28日-【Spark-Streaming-SQL流式处理简介】" class="headerlink" title="8月28日 【Spark Streaming SQL流式处理简介】"></a>8月28日 <a href="https://tianchi.aliyun.com/course/video?liveId=41084" target="_blank" rel="noopener">【Spark Streaming SQL流式处理简介】</a></h3><blockquote><p>本次直播将简要介绍EMR Spark Streaming SQL，主要包含Streaming SQL的语法和使用，最后做demo演示</p></blockquote><h3 id="8月14日-【Spark-Shuffle-优化】"><a href="#8月14日-【Spark-Shuffle-优化】" class="headerlink" title="8月14日 【Spark Shuffle 优化】"></a>8月14日 <a href="https://tianchi.aliyun.com/course/video?liveId=41076" target="_blank" rel="noopener">【Spark Shuffle 优化】</a></h3><blockquote><p>本次直播介绍EMR Spark 在shuffle方面的相关优化工作，主要包含shuffle 优化的背景以及shuffle 优化的设计方案，最后会介绍Spark shuffle 在 TPC-DS测试中的性能数据</p></blockquote><h3 id="7月31日-【Apache-Spark-在存储计算分离趋势下的数据缓存】"><a href="#7月31日-【Apache-Spark-在存储计算分离趋势下的数据缓存】" class="headerlink" title="7月31日 【Apache Spark 在存储计算分离趋势下的数据缓存】"></a>7月31日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41073" target="_blank" rel="noopener">【Apache Spark 在存储计算分离趋势下的数据缓存】</a></h3><blockquote><p>在数据上云的大背景下，存储计算分离逐渐成为了大数据处理的一大趋势，计算引擎需要通过网络读写远端的数据，很多情况下 IO 成为了整个计算任务的瓶颈，因而数据缓存成为此类场景下的一个重要的优化手段。本次分享将介绍 Spark 在数据缓存上的一些做法，并将介绍 EMR 自研的 Jindo 存储系统在数据缓存上的应用。</p></blockquote><h3 id="7月24日-【Apache-Spark-基于-Apache-Arrow-的列式存储优化】"><a href="#7月24日-【Apache-Spark-基于-Apache-Arrow-的列式存储优化】" class="headerlink" title="7月24日 【Apache Spark 基于 Apache Arrow 的列式存储优化】"></a>7月24日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41070" target="_blank" rel="noopener">【Apache Spark 基于 Apache Arrow 的列式存储优化】</a></h3><blockquote><p>Apache Arrow 是一个基于内存的列式存储标准，旨在解决数据交换和传输过程中，序列化和反序列化带来的开销。目前，Apache Spark 社区的一些重要优化都在围绕 Apache Arrow 展开，本次分享会介绍 Apache Arrow 并分析通过 Arrow 将给 Spark 带来哪些特性。</p></blockquote><h3 id="7月3日-【Koalas-介绍】"><a href="#7月3日-【Koalas-介绍】" class="headerlink" title="7月3日 【Koalas 介绍】"></a>7月3日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41058" target="_blank" rel="noopener">【Koalas 介绍】</a></h3><blockquote><p>Koalas是Spark社区推出的新项目，旨在为Spark提供与pandas完全兼容的接口，在降低pandas用户的学习和迁移成本的同时，充分利用Spark强大的分布式处理能力。本次分享介绍Koalas的基本用法和原理。</p></blockquote><h3 id="6月26日-【Spark-Relational-Cache-原理和实践】"><a href="#6月26日-【Spark-Relational-Cache-原理和实践】" class="headerlink" title="6月26日 【Spark Relational Cache 原理和实践】"></a>6月26日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41050" target="_blank" rel="noopener">【Spark Relational Cache 原理和实践】</a></h3><blockquote><p>主要介绍Relational Cache/物化视图的历史和背景，以及EMR Spark基于Relational Cache加速Spark查询的技术方案，及如何通过基于Relational Cache的数据预计算和预组织，使用Spark支持亚秒级响应的交互式分析使用场景。</p></blockquote><h3 id="6与19日-【MLFlow和spark在机器学习方面的进展、Project-Hydrogen和spark在深度学习方面的进展-】"><a href="#6与19日-【MLFlow和spark在机器学习方面的进展、Project-Hydrogen和spark在深度学习方面的进展-】" class="headerlink" title="6与19日 【MLFlow和spark在机器学习方面的进展、Project Hydrogen和spark在深度学习方面的进展 】"></a>6与19日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41008" target="_blank" rel="noopener">【MLFlow和spark在机器学习方面的进展、Project Hydrogen和spark在深度学习方面的进展 】</a></h3><blockquote><p>mlflow为企业提供一套开源的机器学习端到端工具，同时，project hydrogen项目旨在将AI框架与Spark更好的结合。本次直播介绍mlflow的场景和使用方式，project hydrogen的进展以及我们如何通过project hydrogen提供的能力更好的将Spark与AI结合。</p></blockquote><h3 id="6月6日-【Structured-Steaming的进阶与实践-】"><a href="#6月6日-【Structured-Steaming的进阶与实践-】" class="headerlink" title="6月6日 【Structured Steaming的进阶与实践 】"></a>6月6日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41051" target="_blank" rel="noopener">【Structured Steaming的进阶与实践 】</a></h3><blockquote><p>structured steaming因其低时延和提供的SQL API等特性被越来越多的企业所使用，作为实时计算的首选。<br>本次分享structured steaming的使用，包含spark 2.4 structured streaming的新特性，API原理和使用场景等的介绍。</p></blockquote><h3 id="5月29日-【Migration-to-Apache-Spark】"><a href="#5月29日-【Migration-to-Apache-Spark】" class="headerlink" title="5月29日 【Migration to Apache Spark】"></a>5月29日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41034" target="_blank" rel="noopener">【Migration to Apache Spark】</a></h3><blockquote><p>Spark因其统一引擎、性能、易用性等特点备受青睐，将大数据处理引擎迁移到Spark已经成为一种趋势(比如将Hive迁移到SparkSQL)，很多大公司也正在实践。<br>本次分享将围绕Hive迁移到SparkSQL进行展开，内容包括介绍大公司迁移流程、遇到的问题以及对Spark做的一些反馈优化。</p></blockquote><h3 id="5月23日-【基于Spark实现的MLSQL如何帮助企业构建数据中台】"><a href="#5月23日-【基于Spark实现的MLSQL如何帮助企业构建数据中台】" class="headerlink" title="5月23日 【基于Spark实现的MLSQL如何帮助企业构建数据中台】"></a>5月23日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41033" target="_blank" rel="noopener">【基于Spark实现的MLSQL如何帮助企业构建数据中台】</a></h3><blockquote><p>本次分享中，分享者会阐述他心目中的数据中台的样子，并且介绍如何基于MLSQL完成数据中台的构建。<br>此外，分享者会也会介绍MLSQL是如何基于Spark来完成这些扩展的，重要的技术点有：<br>1.如何扩展Spark SQL使其成为一个数据专用的语言MLSQL.<br>2.如何实现对各种数据源譬如HDFS/ES/MySQL/MongoDB等细化到列的权限控制。<br>3.如何构建二层RPC通讯强化对Executor的控制，实现对机器学习更好的支持。<br>4.如何支持兼容多版本Spark<br>5.如何避免机器学习中预测阶段无法复用训练时的代码和数据<br>另外，我们也会简单探讨下Databricks公司新开元项目Delta对于数据和机器学习的意义。</p></blockquote><h3 id="5月15日-【Delta-Lake：一种新型的数据湖方案】"><a href="#5月15日-【Delta-Lake：一种新型的数据湖方案】" class="headerlink" title="5月15日 【Delta Lake：一种新型的数据湖方案】"></a>5月15日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219enHW37w&liveId=41027" target="_blank" rel="noopener">【Delta Lake：一种新型的数据湖方案】</a></h3><blockquote><p>Delta Lake 是 Databricks 推出的一种新型的数据湖方案，解决了传统数据湖方案中的诸多痛点。其中的核心组件 Delta 也于近期开源。本次分享将围绕 Delta Lake 和 Delta 的诸多细节展开，如 Delta Lake 的适用场景、技术优势，Delta 的原理实现以及一些高级特性等，并就现有解决方案做横向对比。</p></blockquote><h3 id="4月29日-【Spark-AI-北美峰会参会分享】"><a href="#4月29日-【Spark-AI-北美峰会参会分享】" class="headerlink" title="4月29日 【Spark + AI 北美峰会参会分享】"></a>4月29日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg&liveId=41029" target="_blank" rel="noopener">【Spark + AI 北美峰会参会分享】</a></h3><blockquote><p>Spark + AI 北美峰会 2019 盛况依然，这两天正如火如荼。大会的主题是 Build，Unify，Scale，对此如何理解？砖厂这次有哪些重磅消息和重要发布，并作如何解读？Spark 过去几年发展的基调和线索是什么，从这次峰会上又如何看出 Spark 在未来几年的发展端倪？</p></blockquote><h3 id="1月10日-【微软Azure平台利用Intel-Analytics-Zoo构建AI客服支持实践】"><a href="#1月10日-【微软Azure平台利用Intel-Analytics-Zoo构建AI客服支持实践】" class="headerlink" title="1月10日 【微软Azure平台利用Intel Analytics Zoo构建AI客服支持实践】"></a>1月10日 <a href="https://tianchi.aliyun.com/course/video?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg&liveId=41028" target="_blank" rel="noopener">【微软Azure平台利用Intel Analytics Zoo构建AI客服支持实践】</a></h3><blockquote><p>本次分享将为大家介绍Intel的Analytics Zoo工具包，并分享微软Azure智能客服平台使用Intel Analytics Zoo的实践经验。</p></blockquote><h3 id="12月26日-【大数据列式存储之-Parquet-ORC】"><a href="#12月26日-【大数据列式存储之-Parquet-ORC】" class="headerlink" title="12月26日 【大数据列式存储之 Parquet/ORC】"></a>12月26日 <a href="https://yq.aliyun.com/live/785?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg" target="_blank" rel="noopener">【大数据列式存储之 Parquet/ORC】</a></h3><blockquote><p>Parquet 和 ORC 是大数据生态里最常用到的两个列式存储引擎，这两者在实现上有什异同，哪个效率更好，哪个性能更优，本次分享将和您一起探索两大列式存储。</p></blockquote><h3 id="12月21日-【What’s-New-in-Apache-Spark-2-4-】"><a href="#12月21日-【What’s-New-in-Apache-Spark-2-4-】" class="headerlink" title="12月21日 【What’s New in Apache Spark 2.4?】"></a>12月21日 <a href="https://yq.aliyun.com/live/775?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg" target="_blank" rel="noopener">【What’s New in Apache Spark 2.4?】</a></h3><blockquote><p>This talk will provide an overview of the major features and enhancements in Spark 2.4 release and the upcoming releases and will be followed by a Q&amp;A session.<br>The Apache Spark 2.4 comes packed with a lot of new functionalities: new barrier execution mode, flexible streaming sink, the native AVRO data source, PySpark’s eager evaluation mode, Kubernetes support, higher-order functions, Scala 2.12 support and a lot of other improvements.</p></blockquote><h3 id="12月13日-【Spark-RDD编程入门】"><a href="#12月13日-【Spark-RDD编程入门】" class="headerlink" title="12月13日 【Spark RDD编程入门】"></a>12月13日 <a href="https://yq.aliyun.com/live/720?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg" target="_blank" rel="noopener">【Spark RDD编程入门】</a></h3><blockquote><p>1.Spark、RDD简介<br>2.RDD API简介<br>3.打包与spark-submit<br>4.性能分析与调优基础</p></blockquote><h3 id="12月6日-【机器学习介绍与Spark-MLlib实践】"><a href="#12月6日-【机器学习介绍与Spark-MLlib实践】" class="headerlink" title="12月6日 【机器学习介绍与Spark MLlib实践】"></a>12月6日 <a href="https://yq.aliyun.com/live/693?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg" target="_blank" rel="noopener">【机器学习介绍与Spark MLlib实践】</a></h3><blockquote><p>本次讲座主要面对的是机器学习的入门者，以及想要使用Spark来进行机器学习的用户。我们会介绍一下机器学习相关领域的基础知识，以及机器学习在spark上面的实践，同时给出我们的一些使用建议。</p></blockquote><h3 id="11月27日-【Spark-SQL-实践与优化】"><a href="#11月27日-【Spark-SQL-实践与优化】" class="headerlink" title="11月27日 【Spark SQL 实践与优化】"></a>11月27日 <a href="https://yunqivedio.alicdn.com/od/Kf8Rb1543482700458.mp4?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg&file=Kf8Rb1543482700458.mp4" target="_blank" rel="noopener">【Spark SQL 实践与优化】</a></h3><blockquote><p>1.基本原理<br>2.支持的DataSource介绍<br>3.Hue/Zepplin/Livy周边跟SparkSQL的集成使用等<br>4.SparkSQL优化<br>5.SparkSQL Catalyst优化<br>6.AE优化<br>7.Shuffle优化</p></blockquote><h3 id="12月4日-【从-Spark-Streaming-到-Structured-Streaming"><a href="#12月4日-【从-Spark-Streaming-到-Structured-Streaming" class="headerlink" title="12月4日 【从 Spark Streaming 到 Structured Streaming"></a>12月4日 <a href="https://yq.aliyun.com/live/689?spm=a2c6h.12873639.0.0.3cb3219eoJoJgg" target="_blank" rel="noopener">【从 Spark Streaming 到 Structured Streaming</a></h3><blockquote><p>1.Spark Streaming<br>2.Google Dataow<br>3.Structured Streaming<br>4.Reference</p></blockquote><p><em>参考地址：<a href="https://developer.aliyun.com/article/718783?groupCode=aliyunemr" target="_blank" rel="noopener">https://developer.aliyun.com/article/718783?groupCode=aliyunemr</a></em><br><em>参考地址：<a href="https://mp.weixin.qq.com/s/d4FnXXCJS9SuztUDA2KvTw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/d4FnXXCJS9SuztUDA2KvTw</a></em></p>]]></content>
      
      
      <categories>
          
          <category> saprk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> saprk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据技术官方文档</title>
      <link href="/2020/01/05/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/"/>
      <url>/2020/01/05/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="cloudera"><a href="#cloudera" class="headerlink" title="cloudera"></a>cloudera</h1><ul><li>cloudera源码包下载：<a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a></li></ul><h1 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h1><h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><ul><li>伪分布式hive配置:<a href="https://docs.cloudera.com/documentation/enterprise/5-16-x/topics/cdh_ig_hive_metastore_configure.html" target="_blank" rel="noopener">https://docs.cloudera.com/documentation/enterprise/5-16-x/topics/cdh_ig_hive_metastore_configure.html</a></li></ul><h1 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h1><ul><li>scala安装包: <a href="https://www.scala-lang.org/download/all.html" target="_blank" rel="noopener">https://www.scala-lang.org/download/all.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 官方文档 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CDH5.12单台伪分布式搭建</title>
      <link href="/2020/01/05/CDH5-12%E5%8D%95%E5%8F%B0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA/"/>
      <url>/2020/01/05/CDH5-12%E5%8D%95%E5%8F%B0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h1><blockquote><p>hadoop: 2.6.0<br>cdh: 5.12.0<br>mysql: 5.7.11<br>hive: 1.1.0<br>scala: 2.12.0<br>spark: 2.4.4</p></blockquote><h1 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h1><blockquote><p>1.安装包准备<br>2.安装JDK<br>3.安装mysql<br>4.hadoop部署<br>5.hive部署<br>6.客户端连接hive</p></blockquote><h1 id="cloudera官网下载hadoop-hive-hbase安装包"><a href="#cloudera官网下载hadoop-hive-hbase安装包" class="headerlink" title="cloudera官网下载hadoop,hive,hbase安装包"></a>cloudera官网下载hadoop,hive,hbase安装包</h1><ul><li>在官网下载以cdh5.12结尾的hadoop,hive安装包, 地址：<a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a></li><li>下载JDK, 下载mysql5.11.7,mysql连接jar包</li><li>准备dbeaver的hadoop-common，hive-jdbc-standalone的jar包</li></ul><h1 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;usr&#x2F;java</span><br><span class="line">tar -xzvf jdk-8u45-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F;</span><br><span class="line">#切记必须修正所属⽤户及⽤户组</span><br><span class="line">chown -R root:root &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_45</span><br><span class="line">echo &quot;export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_45&quot; &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">echo &quot;export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$&#123;PATH&#125;&quot; &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">which java</span><br></pre></td></tr></table></figure><h1 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h1><ul><li>参考: <a href="https://blog.chinahufei.com/2019/12/02/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85mysql/" target="_blank" rel="noopener">https://blog.chinahufei.com/2019/12/02/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85mysql/</a></li></ul><h1 id="hadoop部署"><a href="#hadoop部署" class="headerlink" title="hadoop部署"></a>hadoop部署</h1><h3 id="配置-bashrc"><a href="#配置-bashrc" class="headerlink" title="配置.bashrc"></a>配置.bashrc</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> .bashrc</span><br><span class="line"></span><br><span class="line"># Source global definitions</span><br><span class="line">if [ -f &#x2F;etc&#x2F;bashrc ]; then</span><br><span class="line">        . &#x2F;etc&#x2F;bashrc</span><br><span class="line">fi</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;home&#x2F;ruoze&#x2F;app&#x2F;hadoop</span><br><span class="line">export HIVE_HOME&#x3D;&#x2F;home&#x2F;ruoze&#x2F;app&#x2F;hive</span><br><span class="line"></span><br><span class="line">export PATH&#x3D;$&#123;HADOOP_HOME&#125;&#x2F;bin:$&#123;HADOOP_HOME&#125;&#x2F;sbin:$&#123;HIVE_HOME&#125;&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure><ul><li>source .bashrc</li><li>which hdfs</li><li>which hive</li></ul><h3 id="配置信任关系"><a href="#配置信任关系" class="headerlink" title="配置信任关系"></a>配置信任关系</h3><ul><li>ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsa</li><li>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</li><li>chmod 0600 ~/.ssh/authorized_keys</li><li>ssh hadoop001 date</li></ul><h3 id="配置文件及-NN-SNN-DN-RM-NM都以hadoop001启动"><a href="#配置文件及-NN-SNN-DN-RM-NM都以hadoop001启动" class="headerlink" title="配置文件及 NN SNN DN RM NM都以hadoop001启动"></a>配置文件及 NN SNN DN RM NM都以hadoop001启动</h3><ul><li>vi core-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;hadoop001:9000&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;home&#x2F;ruoze&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    </span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>vi hdfs-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop001:9868&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.https-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop001:9869&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>vi slaves<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop001</span><br></pre></td></tr></table></figure></li><li>vi mapred-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>vi yarn-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop001:18088&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li></ul><h3 id="格式化启动"><a href="#格式化启动" class="headerlink" title="格式化启动"></a>格式化启动</h3><ul><li>hdfs namenode -format</li><li>start-dfs.sh</li><li>start-yarn.sh</li><li>jps</li></ul><h3 id="打开网址"><a href="#打开网址" class="headerlink" title="打开网址"></a>打开网址</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;hadoop001:50070</span><br><span class="line">http:&#x2F;&#x2F;hadoop001:18088</span><br><span class="line">云主机 就开启，防火墙端口号</span><br></pre></td></tr></table></figure><h1 id="hive部署"><a href="#hive部署" class="headerlink" title="hive部署"></a>hive部署</h1><h3 id="部署mysql及赋予权限"><a href="#部署mysql及赋予权限" class="headerlink" title="部署mysql及赋予权限"></a>部署mysql及赋予权限</h3><ul><li>grant all privileges on <em>.</em> to hufei@’%’ identified by ‘password’;</li><li>flush privileges;</li></ul><h3 id="配置hive-site-xml"><a href="#配置hive-site-xml" class="headerlink" title="配置hive-site.xml"></a>配置hive-site.xml</h3><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;jdbc:mysql:&#x2F;&#x2F;myhost&#x2F;metastore&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;description&gt;the URL of the MySQL database&lt;&#x2F;description&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;com.mysql.jdbc.Driver&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;hive&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;mypassword&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.autoCreateSchema&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.fixedDatastore&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.autoStartMechanism&lt;&#x2F;name&gt; </span><br><span class="line">  &lt;value&gt;SchemaTable&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt; </span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.metastore.uris&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;value&gt;thrift:&#x2F;&#x2F;&lt;n.n.n.n&gt;:9083&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;description&gt;IP address (or fully-qualified domain name) and port of the metastore host&lt;&#x2F;description&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.schema.verification&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure></li></ul><h3 id="启动metastore-hiveserver2服务"><a href="#启动metastore-hiveserver2服务" class="headerlink" title="启动metastore + hiveserver2服务"></a>启动metastore + hiveserver2服务</h3><ul><li>nohup hive –service  metastore &gt; ~/log/metastore.log 2&gt;&amp;1 &amp;</li><li>nohup  hiveserver2  &gt; ~/log/hiveserver2.log 2&gt;&amp;1 &amp;</li></ul><h3 id="测试hiveserver2服务是否ok"><a href="#测试hiveserver2服务是否ok" class="headerlink" title="测试hiveserver2服务是否ok"></a>测试hiveserver2服务是否ok</h3><ul><li>第一种：beeline<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beeline</span><br><span class="line">!connect jdbc:hive2:&#x2F;&#x2F;ruozedata001:10000&#x2F;default</span><br></pre></td></tr></table></figure></li><li>第二种：hive<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br><span class="line">show databases;</span><br></pre></td></tr></table></figure></li></ul><h1 id="客户端连接hive"><a href="#客户端连接hive" class="headerlink" title="客户端连接hive"></a>客户端连接hive</h1><ul><li>下载dbeaver</li><li>点击连接，导入hadoop-common，hive-jdbc-standalone的jar包</li><li>图形化界面操作书写hive sql</li></ul><h1 id="安装scala"><a href="#安装scala" class="headerlink" title="安装scala"></a>安装scala</h1><ul><li>切换到root用户(su)</li><li>解压scala安装包到/usr/local<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala-2.12.0.tgz -C &#x2F;usr&#x2F;local&#x2F;</span><br></pre></td></tr></table></figure></li><li>添加环境变量 vim /etc/profile<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Scala env</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;scala-2.12.0</span><br><span class="line">export PATH&#x3D;$SCALA_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li><li>配置立即生效(source /etc/profile)</li></ul><h1 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h1><ul><li>切换到hufei用户(su - hufei)</li><li>解压安装包<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-2.4.4-bin-hadoop2.6.tgz -C ~&#x2F;app&#x2F;</span><br></pre></td></tr></table></figure></li><li>创建软连接<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~&#x2F;app&#x2F;</span><br><span class="line">ln -s spark-2.4.4-bin-hadoop2.6 spark</span><br></pre></td></tr></table></figure></li><li>配置spark<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd spark-2.4.4-bin-hadoop2.6&#x2F;conf</span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_45</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;scala-2.12.0</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;home&#x2F;hufei&#x2F;app&#x2F;hadoop</span><br><span class="line">export HADOOP_CONF_DIR&#x3D;&#x2F;&#x2F;home&#x2F;hufei&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop</span><br><span class="line">export SPARK_MASTER_IP&#x3D;hadoop002</span><br><span class="line">export SPARK_MASTER_PORT&#x3D;7077</span><br></pre></td></tr></table></figure></li><li>配置环境变量(vim ~/.bashrc)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#SPARK_HOME</span><br><span class="line">export SPARK_HOME&#x3D;&#x2F;home&#x2F;hadoop&#x2F;apps&#x2F;spark</span><br><span class="line">export PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin</span><br></pre></td></tr></table></figure></li><li>立即生效(source ~/.bashrc)</li><li>启动spark<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~&#x2F;apps&#x2F;spark&#x2F;sbin&#x2F;start-all.sh</span><br><span class="line">jps</span><br></pre></td></tr></table></figure></li><li>访问8080端口</li></ul>]]></content>
      
      
      <categories>
          
          <category> CDH </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>生产中Hdoop集群规划</title>
      <link href="/2019/12/31/%E7%94%9F%E4%BA%A7%E4%B8%ADHdoop%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/"/>
      <url>/2019/12/31/%E7%94%9F%E4%BA%A7%E4%B8%ADHdoop%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> CDH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS操作合集</title>
      <link href="/2019/12/23/HDFS%E6%93%8D%E4%BD%9C%E5%90%88%E9%9B%86/"/>
      <url>/2019/12/23/HDFS%E6%93%8D%E4%BD%9C%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS读写"><a href="#HDFS读写" class="headerlink" title="HDFS读写"></a>HDFS读写</h1><h3 id="HDFS读文件"><a href="#HDFS读文件" class="headerlink" title="HDFS读文件"></a>HDFS读文件</h3><ul><li>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址</li><li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li><li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。</li><li>客户端以packet为单位接收，先在本地缓存，然后写入目标文件。</li></ul><h3 id="HDFS写文件"><a href="#HDFS写文件" class="headerlink" title="HDFS写文件"></a>HDFS写文件</h3><ul><li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</li><li>NameNode返回是否可以上传。</li><li>客户端请求第一个 block上传到哪几个datanode服务器上。</li><li>NameNode返回多个个datanode节点，分别为dn1、dn2、dn3…。</li><li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</li><li>dn1、dn2、dn3逐级应答客户端。</li><li>客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li><li>当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。</li></ul><p><strong>在传输过程中，如果dn2、dn3挂了，则NameNode在接收到到Client传输完成时，会检查副本数量是否足够，不够的话异步复制少的副本。如果dn1挂了，那么client会再次请求NameNode，再获取几个节点，NameNode将之前元数据修改，并让对应dn删除对应数据</strong></p><h1 id="HDFS命令"><a href="#HDFS命令" class="headerlink" title="HDFS命令"></a>HDFS命令</h1><blockquote><p>主要命令方式有：<br>hadoop fs *<br>hadoop dfs *<br>hdfs dfs *</p></blockquote><ul><li>查看帮助: hdfs dfs -help</li><li>查看当前目录信息: hdfs dfs -ls /</li><li>上传文件: hdfs dfs -put /本地路径 /hdfs路径</li><li>剪切文件: hdfs dfs -moveFromLocal a.txt /aa.txt</li><li>下载文件到本地: hdfs dfs -get /hdfs路径 /本地路径</li><li>合并下载: hdfs dfs -getmerge /hdfs路径文件夹 /合并后的文件</li><li>创建文件夹: hdfs dfs -mkdir /hello</li><li>创建多级文件夹: hdfs dfs -mkdir -p /hello/world</li><li>移动hdfs文件: hdfs dfs -mv /hdfs路径 /hdfs路径</li><li>复制hdfs文件: hdfs dfs -cp /hdfs路径 /hdfs路径</li><li>删除hdfs文件: hdfs dfs -rm /aa.txt</li><li>删除hdfs文件夹: hdfs dfs -rm -r /hello</li><li>查看hdfs中的文件内容: hdfs dfs -cat /文件 | hdfs dfs -tail -f /文件</li><li>查看hdfs的总空间:  hdfs dfs -df / | hdfs dfs -df -h /</li><li>修改副本数: hdfs dfs -setrep 1 /a.txt</li><li>查看目录中所有文件大小: hdfs dfs -du hdfs://host:port/user/hadoop/dir1<h1 id="Java操作HDFS"><a href="#Java操作HDFS" class="headerlink" title="Java操作HDFS"></a>Java操作HDFS</h1></li></ul><h1 id="Scala操作HDFS"><a href="#Scala操作HDFS" class="headerlink" title="Scala操作HDFS"></a>Scala操作HDFS</h1>]]></content>
      
      
      <categories>
          
          <category> HDFS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之TP5技能合集</title>
      <link href="/2019/12/22/PHP%E4%B9%8BTP5%E6%8A%80%E8%83%BD%E5%90%88%E9%9B%86/"/>
      <url>/2019/12/22/PHP%E4%B9%8BTP5%E6%8A%80%E8%83%BD%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="TP5相关解决问题"><a href="#TP5相关解决问题" class="headerlink" title="TP5相关解决问题"></a>TP5相关解决问题</h1><h3 id="1-默认入口文件public-其他文件不允许访问"><a href="#1-默认入口文件public-其他文件不允许访问" class="headerlink" title="1.默认入口文件public,其他文件不允许访问"></a>1.默认入口文件public,其他文件不允许访问</h3><h3 id="2-在application内部，后台一般放在admin内，前台代码一般放在index内，遵循MVC架构"><a href="#2-在application内部，后台一般放在admin内，前台代码一般放在index内，遵循MVC架构" class="headerlink" title="2.在application内部，后台一般放在admin内，前台代码一般放在index内，遵循MVC架构"></a>2.在application内部，后台一般放在admin内，前台代码一般放在index内，遵循MVC架构</h3><h3 id="3-application文件夹中的文件作用"><a href="#3-application文件夹中的文件作用" class="headerlink" title="3.application文件夹中的文件作用"></a>3.application文件夹中的文件作用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- command.php 命令行启动TP5框架需要读取的文件</span><br><span class="line">- common.php 常用的函数，都写在这个文件中</span><br><span class="line">- config.php 配置文件，开启什么，关闭什么，都在这设置</span><br><span class="line">- database.php 连接数据库时候读取的文件，比如用户名</span><br><span class="line">- route.php 路由文件，美化url的</span><br><span class="line">- tags.php 扩展框架的时候用到</span><br></pre></td></tr></table></figure><h3 id="4-public内文件作用"><a href="#4-public内文件作用" class="headerlink" title="4.public内文件作用"></a>4.public内文件作用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- static 这里放的是css、html之类的静态文件</span><br><span class="line">- favicon.ico 这个是网站图标，在标签栏显示的</span><br><span class="line">- index.php 网站入口文件，所有的请求都会经过这里</span><br><span class="line">- robots.txt 禁止搜索引擎爬取页面的设置</span><br><span class="line">- router.php 在没有部署网站环境的情况下，配置这个文件可以让网站运行</span><br></pre></td></tr></table></figure><h3 id="开发规范"><a href="#开发规范" class="headerlink" title="开发规范"></a>开发规范</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 目录 只是小写字母和下划线构成</span><br><span class="line">- 类的文件名以命名空间定义，并且命名空间和类库文件所在路径一致。</span><br><span class="line">- 类的文件采用驼峰，并且首字母大写，其余文件为小写加下划线。</span><br><span class="line">- 类名和类文件名保持一致，采用驼峰命名，首字母大写。</span><br><span class="line">- 函数使用驼峰命名，首字母小写。</span><br><span class="line">- 属性名采用驼峰，首字母小写</span><br><span class="line">- 以双下划线开头的函数或方法为魔术方法。</span><br><span class="line">- 常量以大写字母和下划线命名</span><br><span class="line">- 表和字段必须以小写字母和下划线命名方式，不能以下划线开头。</span><br></pre></td></tr></table></figure><h1 id="apache配置根目录"><a href="#apache配置根目录" class="headerlink" title="apache配置根目录"></a>apache配置根目录</h1><ul><li>修改vhosts.conf<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;VirtualHost _default_:80&gt;</span><br><span class="line">DocumentRoot &quot;C:\phpStudy\PHPTutorial\WWW\public&quot;</span><br><span class="line">    ServerName localhost</span><br><span class="line">    ServerAlias localhost</span><br><span class="line">  &lt;Directory &quot;C:\phpStudy\PHPTutorial\WWW\public&quot;&gt;</span><br><span class="line">    #下面被注释的代码，用“localhost”访问时会禁止访问</span><br><span class="line">    #Options -Indexes -FollowSymLinks +ExecCGI</span><br><span class="line">    Options FollowSymLinks ExecCGI</span><br><span class="line">    AllowOverride All</span><br><span class="line">    Order allow,deny</span><br><span class="line">    Allow from all</span><br><span class="line">    Require all granted</span><br><span class="line">  &lt;&#x2F;Directory&gt;</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br><span class="line"></span><br><span class="line">&lt;VirtualHost *:80&gt;</span><br><span class="line">    DocumentRoot &quot;C:\phpStudy\PHPTutorial\WWW\public&quot;</span><br><span class="line">    ServerName www.gohosts.com</span><br><span class="line">    ServerAlias gohosts.com</span><br><span class="line">  &lt;Directory &quot;C:\phpStudy\PHPTutorial\WWW\public&quot;&gt;</span><br><span class="line">      Options FollowSymLinks ExecCGI</span><br><span class="line">      AllowOverride All</span><br><span class="line">      Order allow,deny</span><br><span class="line">      Allow from all</span><br><span class="line">     Require all granted</span><br><span class="line">  &lt;&#x2F;Directory&gt;</span><br><span class="line">&lt;&#x2F;VirtualHost&gt;</span><br></pre></td></tr></table></figure></li></ul><h1 id="apache配置伪静态"><a href="#apache配置伪静态" class="headerlink" title="apache配置伪静态"></a>apache配置伪静态</h1><ul><li>httpd.conf</li><li>去掉LoadModule rewrite_module前面的#</li><li>AllowOverride None 替换为 AllowOverride All(有多处设置，需要替换)然后保存</li><li>在相应的目录下，添加.htacces文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;IfModule mod_rewrite.c&gt;</span><br><span class="line">  Options +FollowSymlinks -Multiviews</span><br><span class="line">  RewriteEngine On</span><br><span class="line"></span><br><span class="line">  RewriteCond %&#123;REQUEST_FILENAME&#125; !-d</span><br><span class="line">  RewriteCond %&#123;REQUEST_FILENAME&#125; !-f</span><br><span class="line">  RewriteRule ^(.*)$ index.php [L,E&#x3D;PATH_INFO:$1]</span><br><span class="line">&lt;&#x2F;IfModule&gt;</span><br></pre></td></tr></table></figure></li></ul><h1 id="iis配置伪静态"><a href="#iis配置伪静态" class="headerlink" title="iis配置伪静态"></a>iis配置伪静态</h1><ul><li>添加web.config文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;system.webServer&gt;</span><br><span class="line">    &lt;rewrite&gt;</span><br><span class="line">      &lt;rules&gt;</span><br><span class="line">        &lt;rule name&#x3D;&quot;cms&quot;&gt;</span><br><span class="line">          &lt;match url&#x3D;&quot;^cms&#x2F;(.*)$&quot; &#x2F;&gt;  </span><br><span class="line">          &lt;action type&#x3D;&quot;Rewrite&quot; url&#x3D;&quot;&#x2F;public&#x2F;cms&#x2F;pages&#x2F;&#123;R:1&#125;&quot; &#x2F;&gt; </span><br><span class="line">&lt;&#x2F;rule&gt;</span><br><span class="line">        &lt;rule name&#x3D;&quot;OrgPage&quot; stopProcessing&#x3D;&quot;true&quot;&gt;</span><br><span class="line">          &lt;match url&#x3D;&quot;^(.*)$&quot; &#x2F;&gt;</span><br><span class="line">          &lt;conditions logicalGrouping&#x3D;&quot;MatchAll&quot;&gt;</span><br><span class="line">            &lt;add input&#x3D;&quot;&#123;HTTP_HOST&#125;&quot; pattern&#x3D;&quot;^(.*)$&quot; &#x2F;&gt;</span><br><span class="line">            &lt;add input&#x3D;&quot;&#123;REQUEST_FILENAME&#125;&quot; matchType&#x3D;&quot;IsFile&quot; negate&#x3D;&quot;true&quot; &#x2F;&gt;</span><br><span class="line">            &lt;add input&#x3D;&quot;&#123;REQUEST_FILENAME&#125;&quot; matchType&#x3D;&quot;IsDirectory&quot; negate&#x3D;&quot;true&quot; &#x2F;&gt;</span><br><span class="line">          &lt;&#x2F;conditions&gt;</span><br><span class="line">          &lt;action type&#x3D;&quot;Rewrite&quot; url&#x3D;&quot;&#x2F;public&#x2F;index.php&#x2F;&#123;R:1&#125;&quot; &#x2F;&gt;</span><br><span class="line">        &lt;&#x2F;rule&gt;</span><br><span class="line">      &lt;&#x2F;rules&gt;</span><br><span class="line">    &lt;&#x2F;rewrite&gt;</span><br><span class="line">  &lt;&#x2F;system.webServer&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> PHP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据常用shell脚本</title>
      <link href="/2019/12/08/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B8%B8%E7%94%A8shell%E8%84%9A%E6%9C%AC/"/>
      <url>/2019/12/08/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B8%B8%E7%94%A8shell%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h1 id="shell交互脚本"><a href="#shell交互脚本" class="headerlink" title="shell交互脚本"></a>shell交互脚本</h1><ul><li><p>zkManager.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line">for host in hdp-1 hdp-2 hdp-3</span><br><span class="line">do</span><br><span class="line">echo "$&#123;host&#125;:$&#123;1&#125;ing...."</span><br><span class="line">ssh $host  "source /etc/profile;/root/apps/zookeeper-3.4.6/bin/zkServer.sh $1"</span><br><span class="line">done</span><br><span class="line"> </span><br><span class="line">sleep 2</span><br><span class="line"> </span><br><span class="line">for host in hdp-1 hdp-2 hdp-3</span><br><span class="line">do</span><br><span class="line">ssh $host  "source /etc/profile;/root/apps/zookeeper-3.4.6/bin/zkServer.sh status"</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>start-kafka-cluster.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">brokers="hdp-1 hdp-2 hdp-3"</span><br><span class="line">KAFKA_HOME="/root/apps/kafka_2.12-2.2.0"</span><br><span class="line">KAFKA_NAME="kafka_2.12-2.2.0"</span><br><span class="line"> </span><br><span class="line">echo "开启kafka ..."</span><br><span class="line"> </span><br><span class="line">for broker in $brokers</span><br><span class="line">do</span><br><span class="line">  echo "INFO : Starting $&#123;KAFKA_NAME&#125; on $&#123;broker&#125; ..."</span><br><span class="line">  ssh $&#123;broker&#125; -C "source /etc/profile; sh $&#123;KAFKA_HOME&#125;/bin/kafka-server-start.sh -daemon $&#123;KAFKA_HOME&#125;/config/server.properties"</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>stop-kafka-cluster.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">brokers="hdp-1 hdp-2 hdp-3"</span><br><span class="line">KAFKA_HOME="/root/apps/kafka_2.12-2.2.0"</span><br><span class="line">KAFKA_NAME="kafka_2.12-2.2.0"</span><br><span class="line"> </span><br><span class="line">echo "关闭kafka ..."</span><br><span class="line"> </span><br><span class="line">for broker in $brokers</span><br><span class="line">do</span><br><span class="line">  echo "INFO : Shut down $&#123;KAFKA_NAME&#125; on $&#123;broker&#125; ..."</span><br><span class="line">  ssh $&#123;broker&#125; "source /etc/profile;bash $&#123;KAFKA_HOME&#125;/bin/kafka-server-stop.sh"</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>install-jdk.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">BASE_SERVER=172.16.203.100</span><br><span class="line">yum install -y wget</span><br><span class="line">wget $BASE_SERVER/soft/jdk-7u45-linux-x64.tar.gz</span><br><span class="line">tar -zxvf jdk-7u45-linux-x64.tar.gz -C /usr/local</span><br><span class="line">cat &gt;&gt; /etc/profile &lt;&lt; EOF</span><br><span class="line">export JAVA_HOME=/usr/local/jdk1.7.0_45</span><br><span class="line">export PATH=\$PATH:\$JAVA_HOME/bin</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>boot.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">SERVERS="node-3.itcast.cn node-4.itcast.cn"</span><br><span class="line">PASSWORD=123456</span><br><span class="line">BASE_SERVER=172.16.203.100</span><br><span class="line"></span><br><span class="line">auto_ssh_copy_id() &#123;</span><br><span class="line">    expect -c "set timeout -1;</span><br><span class="line">        spawn ssh-copy-id $1;</span><br><span class="line">        expect &#123;</span><br><span class="line">            *(yes/no)* &#123;send -- yes\r;exp_continue;&#125;</span><br><span class="line">            *assword:* &#123;send -- $2\r;exp_continue;&#125;</span><br><span class="line">            eof        &#123;exit 0;&#125;</span><br><span class="line">        &#125;";</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_copy_id_to_all() &#123;</span><br><span class="line">    for SERVER in $SERVERS</span><br><span class="line">    do</span><br><span class="line">        auto_ssh_copy_id $SERVER $PASSWORD</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ssh_copy_id_to_all</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for SERVER in $SERVERS</span><br><span class="line">do</span><br><span class="line">    scp install.sh root@$SERVER:/root</span><br><span class="line">    ssh root@$SERVER /root/install.sh</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux&amp;Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH搭建问题合集</title>
      <link href="/2019/12/08/CDH%E6%90%AD%E5%BB%BA%E9%97%AE%E9%A2%98%E5%90%88%E9%9B%86/"/>
      <url>/2019/12/08/CDH%E6%90%AD%E5%BB%BA%E9%97%AE%E9%A2%98%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> CDH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo搭建个人博客</title>
      <link href="/2019/12/06/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2019/12/06/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h1><blockquote><p>1.安装Git<br>2.安装Node.js<br>3.安装Hexo<br>4.GitHub创建个人仓库<br>5.生成SSH添加到GitHub<br>6.将hexo部署到GitHub<br>7.设置个人域名<br>8.发布文章</p></blockquote><h1 id="安装git，可以参考git安装那篇博客。"><a href="#安装git，可以参考git安装那篇博客。" class="headerlink" title="安装git，可以参考git安装那篇博客。"></a>安装git，可以参考git安装那篇博客。</h1><h1 id="NodeJs安装，可以参考网上博客，node-v-和-npm-v-有返回值即可。"><a href="#NodeJs安装，可以参考网上博客，node-v-和-npm-v-有返回值即可。" class="headerlink" title="NodeJs安装，可以参考网上博客，node -v 和 npm -v 有返回值即可。"></a>NodeJs安装，可以参考网上博客，node -v 和 npm -v 有返回值即可。</h1><h1 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli # hexo全局脚手架</span><br><span class="line">hexo -v # 查看hexo版本</span><br><span class="line">hexo init blog # 初始化博客</span><br><span class="line">cd blog # 进入hexo目录</span><br><span class="line">npm i # 安装依赖</span><br><span class="line">hexo c # 清除缓存</span><br><span class="line">hexo g # 生成静态页</span><br><span class="line">hexo s # 开启hexo服务，默认端口4000。可以通过localhost:4000查看</span><br><span class="line">hexo d # 部署到github或者coding</span><br></pre></td></tr></table></figure><blockquote><p>node_modules: 依赖包<br>public：存放生成的页面<br>scaffolds：生成文章的一些模板<br>source：用来存放你的文章<br>themes：主题<br>** _config.yml: 博客的配置文件**</p></blockquote><h1 id="github注册账户，参考https-my-oschina-net-chinahufei-blog-1577979"><a href="#github注册账户，参考https-my-oschina-net-chinahufei-blog-1577979" class="headerlink" title="github注册账户，参考https://my.oschina.net/chinahufei/blog/1577979"></a>github注册账户，参考<a href="https://my.oschina.net/chinahufei/blog/1577979" target="_blank" rel="noopener">https://my.oschina.net/chinahufei/blog/1577979</a></h1><h1 id="生成SSH添加到GitHub"><a href="#生成SSH添加到GitHub" class="headerlink" title="生成SSH添加到GitHub"></a>生成SSH添加到GitHub</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;yourname&quot;</span><br><span class="line">git config --global user.email &quot;youremail&quot;</span><br><span class="line">ssh-keygen -t rsa -C &quot;youremail&quot;</span><br><span class="line"># 把id_rsa.pub的文件内容添加到github的public key</span><br><span class="line">ssh -T git@github.com # 检查是否成功</span><br></pre></td></tr></table></figure><h1 id="将hexo部署到GitHub"><a href="#将hexo部署到GitHub" class="headerlink" title="将hexo部署到GitHub"></a>将hexo部署到GitHub</h1><ul><li>配置_config.yml文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https:&#x2F;&#x2F;github.com&#x2F;YourgithubName&#x2F;YourgithubName.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><blockquote><p>npm install hexo-deployer-git –save<br>hexo clean<br>hexo generate<br>hexo deploy</p></blockquote></li></ul><h1 id="设置个人域名"><a href="#设置个人域名" class="headerlink" title="设置个人域名"></a>设置个人域名</h1><ul><li>在域名服务商购买域名</li><li>在域名服务商账户做解析，解析到github对应的github page</li><li>在github page做域名绑定。(登录GitHub，进入之前创建的仓库，点击settings，设置Custom domain，输入你的域名)</li><li>也可以注册一个国内的coding，实现双域名解析，国内解析coding,国外解析github。不过这个需要域名服务商支持国内外双线路解析。</li></ul><h1 id="发布文章"><a href="#发布文章" class="headerlink" title="发布文章"></a>发布文章</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo new newpapername</span><br><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p><em>文章参考：<a href="https://blog.csdn.net/sinat_37781304/article/details/82729029" target="_blank" rel="noopener">https://blog.csdn.net/sinat_37781304/article/details/82729029</a></em></p><h1 id="hexo-使用"><a href="#hexo-使用" class="headerlink" title="hexo 使用"></a>hexo 使用</h1><ul><li>文字说明<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;% blockquote %&#125;</span><br><span class="line">1.安装Git</span><br><span class="line">2.安装Node.js</span><br><span class="line">3.安装Hexo</span><br><span class="line">4.GitHub创建个人仓库</span><br><span class="line">5.生成SSH添加到GitHub</span><br><span class="line">6.将hexo部署到GitHub</span><br><span class="line">7.设置个人域名</span><br><span class="line">8.发布文章</span><br><span class="line">&#123;% endblockquote %&#125;</span><br></pre></td></tr></table></figure></li><li>markdown表格写法<table><thead><tr><th>水果</th><th align="right">价格</th><th align="center">数量</th></tr></thead><tbody><tr><td>香蕉</td><td align="right">$1</td><td align="center">5</td></tr><tr><td>苹果</td><td align="right">$1</td><td align="center">6</td></tr><tr><td>草莓</td><td align="right">$1</td><td align="center">7</td></tr></tbody></table></li></ul>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH5.16.1分布式集群搭建</title>
      <link href="/2019/12/04/CDH5.16.1%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/2019/12/04/CDH5.16.1%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h1><ul><li>CM:<a href="http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz" target="_blank" rel="noopener">http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz</a></li><li>Parcel<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel</span><br><span class="line">http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1</span><br><span class="line">http://archive.cloudera.com/cdh5/parcels/5.16.1/manifest.json</span><br></pre></td></tr></table></figure></li><li>JDK:<a href="https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html</a></li><li>Mysql:<a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.7.html#downloads</a></li><li>Mysql JDBC:<a href="http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar" target="_blank" rel="noopener">http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar</a></li></ul><h1 id="二、集群初始化"><a href="#二、集群初始化" class="headerlink" title="二、集群初始化"></a>二、集群初始化</h1><ul><li>配置host<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 公⽹地址:</span></span><br><span class="line">106.15.234.222 hadoop001</span><br><span class="line">106.15.235.200 hadoop002</span><br><span class="line">106.15.234.239 hadoop003</span><br></pre></td></tr></table></figure></li><li>设置所有节点的hosts⽂件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo "172.19.7.96 hadoop001"&gt;&gt; /etc/hosts</span><br><span class="line">echo "172.19.7.98 hadoop002"&gt;&gt; /etc/hosts</span><br><span class="line">echo "172.19.7.97 hadoop003"&gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure></li><li>关闭所有节点的防⽕墙及清空规则<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">iptables -F</span><br></pre></td></tr></table></figure></li><li>关闭所有节点的selinux<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;selinux&#x2F;config</span><br><span class="line">将SELINUX&#x3D;enforcing改为SELINUX&#x3D;disabled</span><br><span class="line">设置后需要重启才能⽣效</span><br></pre></td></tr></table></figure></li><li>设置所有节点的时区⼀致及时钟同步<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure></li><li>部署JDK<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/java</span><br><span class="line">tar -xzvf jdk-8u45-linux-x64.tar.gz -C /usr/java/</span><br><span class="line"><span class="meta">#</span><span class="bash">切记必须修正所属⽤户及⽤户组</span></span><br><span class="line">chown -R root:root /usr/java/jdk1.8.0_45</span><br><span class="line">echo "export JAVA_HOME=/usr/java/jdk1.8.0_45" &gt;&gt; /etc/profile</span><br><span class="line">echo "export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125;" &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br><span class="line">which java</span><br></pre></td></tr></table></figure></li><li>部署Mysql(见博客)</li><li>创建cm用户<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create database cmf DEFAULT CHARACTER SET utf8;</span><br><span class="line">create database amon DEFAULT CHARACTER SET utf8;</span><br><span class="line">grant all on cmf.* TO &#39;cmf&#39;@&#39;%&#39; IDENTIFIED BY &#39;Ruozedata123456!&#39;;</span><br><span class="line">grant all on amon.* TO &#39;amon&#39;@&#39;%&#39; IDENTIFIED BY &#39;Ruozedata123456!&#39;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></li><li>hadoop001部署Mysql JDBC<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/share/java/</span><br><span class="line">cp mysql-connector-java.jar /usr/share/java/</span><br></pre></td></tr></table></figure></li></ul><h1 id="三、部署CDH"><a href="#三、部署CDH" class="headerlink" title="三、部署CDH"></a>三、部署CDH</h1><ul><li>离线部署 cm server 以及agent<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.1.所有节点创建⽬录及解压</span><br><span class="line">mkdir &#x2F;opt&#x2F;cloudera-manager</span><br><span class="line">tar -zxvf cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz -C &#x2F;opt&#x2F;cloudera-manager&#x2F;</span><br><span class="line">1.2.所有节点修改agent的配置，指向server的节点hadoop001</span><br><span class="line">sed -i &quot;s&#x2F;server_host&#x3D;localhost&#x2F;server_host&#x3D;hadoop001&#x2F;g&quot; &#x2F;opt&#x2F;cloudera-manager&#x2F;cm5.16.1&#x2F;etc&#x2F;cloudera-scm-agent&#x2F;config.ini</span><br><span class="line">1.3.主节点修改server的配置:</span><br><span class="line">vi &#x2F;opt&#x2F;cloudera-manager&#x2F;cm-5.16.1&#x2F;etc&#x2F;cloudera-scm-server&#x2F;db.properties</span><br><span class="line">com.cloudera.cmf.db.type&#x3D;mysql</span><br><span class="line">com.cloudera.cmf.db.host&#x3D;hadoop001</span><br><span class="line">com.cloudera.cmf.db.name&#x3D;cmf</span><br><span class="line">com.cloudera.cmf.db.user&#x3D;cmf</span><br><span class="line">com.cloudera.cmf.db.password&#x3D;Ruozedata123456!</span><br><span class="line">com.cloudera.cmf.db.setupType&#x3D;EXTERNAL</span><br><span class="line">1.4.所有节点创建⽤户</span><br><span class="line">useradd --system --home&#x3D;&#x2F;opt&#x2F;cloudera-manager&#x2F;cm-5.16.1&#x2F;run&#x2F;cloudera-scm-server&#x2F; --no-create-home --shell&#x3D;&#x2F;bin&#x2F;false --comment &quot;Cloudera SCM User&quot; cloudera-scm</span><br><span class="line">1.5.⽬录修改⽤户及⽤户组</span><br><span class="line">chown -R cloudera-scm:cloudera-scm &#x2F;opt&#x2F;cloudera-manager</span><br></pre></td></tr></table></figure></li><li>hadoop001节点部署离线parcel源<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2.1.部署离线parcel源</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo</span><br><span class="line">cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F;</span><br><span class="line">#切记cp时，重命名去掉1，不然在部署过程CM认为如上⽂件下载未完整，会持续下载</span><br><span class="line">cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1 &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F;CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha</span><br><span class="line">cp manifest.json &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F;</span><br><span class="line">2.2.⽬录修改⽤户及⽤户组</span><br><span class="line">chown -R cloudera-scm:cloudera-scm &#x2F;opt&#x2F;cloudera&#x2F;</span><br></pre></td></tr></table></figure></li><li>所有节点创建软件安装⽬录、⽤户及⽤户组权限<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;cloudera&#x2F;parcels chown -R cloudera-scm:cloudera-scm &#x2F;opt&#x2F;cloudera&#x2F;</span><br></pre></td></tr></table></figure></li><li>hadoop001节点启动Server<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">4.1.启动server</span><br><span class="line">&#x2F;opt&#x2F;cloudera-manager&#x2F;cm-5.16.1&#x2F;etc&#x2F;init.d&#x2F;cloudera-scm-server start</span><br><span class="line">4.2.阿⾥云web界⾯，设置该hadoop001节点防⽕墙放开7180端⼝</span><br><span class="line">4.3.等待1min，打开 http:&#x2F;&#x2F;hadoop001:7180 账号密码:admin&#x2F;admin</span><br><span class="line">4.4.假如打不开，去看server的log，根据错误仔细排查错误</span><br></pre></td></tr></table></figure></li><li>注意点<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">13.1.建议将&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness设置为最⼤值10。</span><br><span class="line">swappiness值控制操作系统尝试交换内存的积极；</span><br><span class="line">swappiness&#x3D;0：表示最⼤限度使⽤物理内存，之后才是swap空间；</span><br><span class="line">swappiness&#x3D;100：表示积极使⽤swap分区，并且把内存上的数据及时搬迁到swap空间；</span><br><span class="line">如果是混合服务器，不建议完全禁⽤swap，可以尝试降低swappiness。</span><br><span class="line">临时调整：</span><br><span class="line">sysctl vm.swappiness&#x3D;10</span><br><span class="line">永久调整：</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"># Adjust swappiness value</span><br><span class="line">vm.swappiness&#x3D;10</span><br><span class="line">EOF</span><br><span class="line">13.2.已启⽤透明⼤⻚⾯压缩，可能会导致重⼤性能问题，建议禁⽤此设置。</span><br><span class="line">临时调整：</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defrag</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled</span><br><span class="line">永久调整：</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local</span><br><span class="line"># Disable transparent_hugepage</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defrag</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled</span><br><span class="line">EOF</span><br><span class="line"># centos7.x系统，需要为&quot;&#x2F;etc&#x2F;rc.d&#x2F;rc.local&quot;⽂件赋予执⾏权限</span><br><span class="line">chmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> CDH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产环境离线安装Mysql</title>
      <link href="/2019/12/02/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85Mysql/"/>
      <url>/2019/12/02/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85Mysql/</url>
      
        <content type="html"><![CDATA[<h1 id="Centos7-生产环境安装mysql"><a href="#Centos7-生产环境安装mysql" class="headerlink" title="Centos7 生产环境安装mysql"></a>Centos7 生产环境安装mysql</h1><h3 id="1-解压及创建目录"><a href="#1-解压及创建目录" class="headerlink" title="1.解压及创建目录"></a>1.解压及创建目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf mysql-5.7.11-linux-glibc2.5-x86_64.tar.gz</span><br><span class="line">mv mysql-5.7.11-linux-glibc2.5-x86_64 mysql</span><br><span class="line">mv mysql /usr/local</span><br><span class="line">chown -R root:root mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在<span class="built_in">local</span>目录下</span></span><br><span class="line">mkdir mysql/arch mysql/data mysql/tmp</span><br></pre></td></tr></table></figure><h3 id="2-创建my-cnf"><a href="#2-创建my-cnf" class="headerlink" title="2.创建my.cnf"></a>2.创建my.cnf</h3><ul><li>vi /etc/my.cnf<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">port            &#x3D; 3306</span><br><span class="line">socket          &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.sock</span><br><span class="line">default-character-set&#x3D;utf8mb4</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">port            &#x3D; 3306</span><br><span class="line">socket          &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.sock</span><br><span class="line"></span><br><span class="line">skip-slave-start</span><br><span class="line"></span><br><span class="line">skip-external-locking</span><br><span class="line">key_buffer_size &#x3D; 256M</span><br><span class="line">sort_buffer_size &#x3D; 2M</span><br><span class="line">read_buffer_size &#x3D; 2M</span><br><span class="line">read_rnd_buffer_size &#x3D; 4M</span><br><span class="line">query_cache_size&#x3D; 32M</span><br><span class="line">max_allowed_packet &#x3D; 16M</span><br><span class="line">myisam_sort_buffer_size&#x3D;128M</span><br><span class="line">tmp_table_size&#x3D;32M</span><br><span class="line"></span><br><span class="line">table_open_cache &#x3D; 512</span><br><span class="line">thread_cache_size &#x3D; 8</span><br><span class="line">wait_timeout &#x3D; 86400</span><br><span class="line">interactive_timeout &#x3D; 86400</span><br><span class="line">max_connections &#x3D; 600</span><br><span class="line"></span><br><span class="line"># Try number of CPU&#39;s*2 for thread_concurrency</span><br><span class="line">#thread_concurrency &#x3D; 32 </span><br><span class="line"></span><br><span class="line">#isolation level and default engine </span><br><span class="line">default-storage-engine &#x3D; INNODB</span><br><span class="line">transaction-isolation &#x3D; READ-COMMITTED</span><br><span class="line"></span><br><span class="line">server-id  &#x3D; 1739</span><br><span class="line">basedir     &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">datadir     &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data</span><br><span class="line">pid-file     &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;hostname.pid</span><br><span class="line"></span><br><span class="line">#open performance schema</span><br><span class="line">log-warnings</span><br><span class="line">sysdate-is-now</span><br><span class="line"></span><br><span class="line">binlog_format &#x3D; ROW</span><br><span class="line">log_bin_trust_function_creators&#x3D;1</span><br><span class="line">log-error  &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;hostname.err</span><br><span class="line">log-bin &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;arch&#x2F;mysql-bin</span><br><span class="line">expire_logs_days &#x3D; 7</span><br><span class="line"></span><br><span class="line">innodb_write_io_threads&#x3D;16</span><br><span class="line"></span><br><span class="line">relay-log  &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;relay_log&#x2F;relay-log</span><br><span class="line">relay-log-index &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;relay_log&#x2F;relay-log.index</span><br><span class="line">relay_log_info_file&#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;relay_log&#x2F;relay-log.info</span><br><span class="line"></span><br><span class="line">log_slave_updates&#x3D;1</span><br><span class="line">gtid_mode&#x3D;OFF</span><br><span class="line">enforce_gtid_consistency&#x3D;OFF</span><br><span class="line"></span><br><span class="line"># slave</span><br><span class="line">slave-parallel-type&#x3D;LOGICAL_CLOCK</span><br><span class="line">slave-parallel-workers&#x3D;4</span><br><span class="line">master_info_repository&#x3D;TABLE</span><br><span class="line">relay_log_info_repository&#x3D;TABLE</span><br><span class="line">relay_log_recovery&#x3D;ON</span><br><span class="line"></span><br><span class="line">#other logs</span><br><span class="line">#general_log &#x3D;1</span><br><span class="line">#general_log_file  &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;general_log.err</span><br><span class="line">#slow_query_log&#x3D;1</span><br><span class="line">#slow_query_log_file&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;slow_log.err</span><br><span class="line"></span><br><span class="line">#for replication slave</span><br><span class="line">sync_binlog &#x3D; 500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#for innodb options </span><br><span class="line">innodb_data_home_dir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;</span><br><span class="line">innodb_data_file_path &#x3D; ibdata1:1G;ibdata2:1G:autoextend</span><br><span class="line"></span><br><span class="line">innodb_log_group_home_dir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;arch</span><br><span class="line">innodb_log_files_in_group &#x3D; 4</span><br><span class="line">innodb_log_file_size &#x3D; 1G</span><br><span class="line">innodb_log_buffer_size &#x3D; 200M</span><br><span class="line"></span><br><span class="line">#根据生产需要，调整pool size </span><br><span class="line">innodb_buffer_pool_size &#x3D; 2G</span><br><span class="line">#innodb_additional_mem_pool_size &#x3D; 50M #deprecated in 5.6</span><br><span class="line">tmpdir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;tmp</span><br><span class="line"></span><br><span class="line">innodb_lock_wait_timeout &#x3D; 1000</span><br><span class="line">#innodb_thread_concurrency &#x3D; 0</span><br><span class="line">innodb_flush_log_at_trx_commit &#x3D; 2</span><br><span class="line"></span><br><span class="line">innodb_locks_unsafe_for_binlog&#x3D;1</span><br><span class="line"></span><br><span class="line">#innodb io features: add for mysql5.5.8</span><br><span class="line">performance_schema</span><br><span class="line">innodb_read_io_threads&#x3D;4</span><br><span class="line">innodb-write-io-threads&#x3D;4</span><br><span class="line">innodb-io-capacity&#x3D;200</span><br><span class="line">#purge threads change default(0) to 1 for purge</span><br><span class="line">innodb_purge_threads&#x3D;1</span><br><span class="line">innodb_use_native_aio&#x3D;on</span><br><span class="line"></span><br><span class="line">#case-sensitive file names and separate tablespace</span><br><span class="line">innodb_file_per_table &#x3D; 1</span><br><span class="line">lower_case_table_names&#x3D;1</span><br><span class="line"></span><br><span class="line">[mysqldump]</span><br><span class="line">quick</span><br><span class="line">max_allowed_packet &#x3D; 128M</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">no-auto-rehash</span><br><span class="line">default-character-set&#x3D;utf8mb4</span><br><span class="line"></span><br><span class="line">[mysqlhotcopy]</span><br><span class="line">interactive-timeout</span><br><span class="line"></span><br><span class="line">[myisamchk]</span><br><span class="line">key_buffer_size &#x3D; 256M</span><br><span class="line">sort_buffer_size &#x3D; 256M</span><br><span class="line">read_buffer &#x3D; 2M</span><br><span class="line">write_buffer &#x3D; 2M</span><br></pre></td></tr></table></figure><h3 id="3-创建用户组及用户"><a href="#3-创建用户组及用户" class="headerlink" title="3.创建用户组及用户"></a>3.创建用户组及用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">groupadd -g 101 dba</span><br><span class="line">useradd -u 514 -g dba -G root -d /usr/local/mysql mysqladmin</span><br><span class="line">id mysqladmin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 一般不需要设置mysqladmin的密码，直接从root或者LDAP用户sudo切换</span></span><br><span class="line">passwd mysqladmin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入两次密码</span></span><br><span class="line">usermod -u 514 -g dba -G root -d /usr/local/mysql mysqladmin</span><br></pre></td></tr></table></figure><h3 id="4-copy-环境变量配置文件至mysqladmin用户的home目录中-为了以下步骤配置个人环境变量"><a href="#4-copy-环境变量配置文件至mysqladmin用户的home目录中-为了以下步骤配置个人环境变量" class="headerlink" title="4.copy 环境变量配置文件至mysqladmin用户的home目录中,为了以下步骤配置个人环境变量"></a>4.copy 环境变量配置文件至mysqladmin用户的home目录中,为了以下步骤配置个人环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/skel/.* /usr/local/mysql  ###important</span><br></pre></td></tr></table></figure><h3 id="5-配置环境变量"><a href="#5-配置环境变量" class="headerlink" title="5.配置环境变量"></a>5.配置环境变量</h3></li><li>vi mysql/.bash_profile</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># .bash_profile</span><br><span class="line"># Get the aliases and functions</span><br><span class="line"></span><br><span class="line">if [ -f ~&#x2F;.bashrc ]; then</span><br><span class="line">        . ~&#x2F;.bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># User specific environment and startup programs</span><br><span class="line">export MYSQL_BASE&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">export PATH&#x3D;$&#123;MYSQL_BASE&#125;&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">unset USERNAME</span><br><span class="line"></span><br><span class="line">#stty erase ^H</span><br><span class="line">set umask to 022</span><br><span class="line">umask 022</span><br><span class="line">PS1&#x3D;&#96;uname -n&#96;&quot;:&quot;&#39;$USER&#39;&quot;:&quot;&#39;$PWD&#39;&quot;:&gt;&quot;; export PS1</span><br><span class="line"></span><br><span class="line">## end</span><br></pre></td></tr></table></figure><h3 id="6-赋权限和用户组，切换用户mysqladmin，安装"><a href="#6-赋权限和用户组，切换用户mysqladmin，安装" class="headerlink" title="6.赋权限和用户组，切换用户mysqladmin，安装"></a>6.赋权限和用户组，切换用户mysqladmin，安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chown  mysqladmin:dba /etc/my.cnf</span><br><span class="line">chmod  640 /etc/my.cnf</span><br><span class="line">chown -R mysqladmin:dba /usr/local/mysql</span><br><span class="line">chmod -R 755 /usr/local/mysql</span><br></pre></td></tr></table></figure><h3 id="7-配置服务及开机自启动"><a href="#7-配置服务及开机自启动" class="headerlink" title="7.配置服务及开机自启动"></a>7.配置服务及开机自启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将服务文件拷贝到init.d下，并重命名为mysql</span></span><br><span class="line">cp support-files/mysql.server /etc/rc.d/init.d/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 赋予可执行权限</span></span><br><span class="line">chmod +x /etc/rc.d/init.d/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除服务</span></span><br><span class="line">chkconfig --del mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加服务</span></span><br><span class="line">chkconfig --add mysql</span><br><span class="line">chkconfig --level 345 mysql on</span><br></pre></td></tr></table></figure><h3 id="8-安装libaio及安装mysql的初始db"><a href="#8-安装libaio及安装mysql的初始db" class="headerlink" title="8.安装libaio及安装mysql的初始db"></a>8.安装libaio及安装mysql的初始db</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yum -y install libaio</span><br><span class="line">sudo su - mysqladmin</span><br><span class="line">bin/mysqld \</span><br><span class="line">--defaults-file=/etc/my.cnf \</span><br><span class="line">--user=mysqladmin \</span><br><span class="line">--basedir=/usr/local/mysql/ \</span><br><span class="line">--datadir=/usr/local/mysql/data/ \</span><br><span class="line">--initialize</span><br><span class="line"><span class="meta">#</span><span class="bash">　在初始化时如果加上 –initial-insecure，则会创建空密码的 root@localhost 账号，否则会创建带密码的 root@localhost 账号，密码直接写在 <span class="built_in">log</span>-error 日志文件中</span></span><br><span class="line"><span class="meta">#</span><span class="bash">  （在5.6版本中是放在 ~/.mysql_secret 文件里，更加隐蔽，不熟悉的话可能会无所适从）</span></span><br><span class="line">cd data</span><br><span class="line">cat hostname.err |grep password # 查看临时密码，复制保存</span><br><span class="line">cd ..</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动mysql，2次回车</span></span><br><span class="line">/usr/local/mysql/bin/mysqld_safe --defaults-file=/etc/my.cnf &amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看状态</span></span><br><span class="line">service mysql status</span><br></pre></td></tr></table></figure><h3 id="9-查看mysql是否成功启动"><a href="#9-查看mysql是否成功启动" class="headerlink" title="9.查看mysql是否成功启动"></a>9.查看mysql是否成功启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">exit; # 退出</span><br><span class="line">ps -ef | grep mysql  # 查看mysql端口</span><br><span class="line">netstat -nlp | grep 12022 # 查看端口对应的服务，能看到3306端口</span><br><span class="line">su - mysqladmin</span><br></pre></td></tr></table></figure><h3 id="10-登录及修改用户密码-重启"><a href="#10-登录及修改用户密码-重启" class="headerlink" title="10.登录及修改用户密码, 重启"></a>10.登录及修改用户密码, 重启</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p'*****' # *****是复制的临时密码</span><br><span class="line">alter user root@localhost identified by 'hufei123456';</span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'hufei123456' ;</span><br><span class="line">flush privileges;</span><br><span class="line">exit;</span><br><span class="line">service mysql restart</span><br><span class="line">mysql -uroot -hufei123456</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows中大数据开发环境及工具配置</title>
      <link href="/2019/12/01/Windows%E4%B8%AD%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/"/>
      <url>/2019/12/01/Windows%E4%B8%AD%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME ： C:\Program Files (x86)\Java\jdk1.8.0_60（此目录为jdk主目录）</span><br><span class="line">Path ：%JAVA_HOME%\bin</span><br><span class="line">classPath ： .;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar（别错过前面的点）</span><br><span class="line">Idea中添加JDK : File--&gt;Project Structure--&gt;SDKS--&gt;添加</span><br></pre></td></tr></table></figure><h1 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">MAVEN_HOME ： D:\Program Files\Apache\maven（此目录为Maven安装目录）</span><br><span class="line">Path ：%MAVEN_HOME%\bin\;</span><br><span class="line">MAVEN_OPTS : -Xms128m -Xmx512m -Duser.language&#x3D;zh -Dfile.encoding&#x3D;UTF-8</span><br><span class="line"># 配置本地仓库</span><br><span class="line">D:\Program Files\Apache\maven\conf\settings.xml</span><br><span class="line">&lt;localRepository&gt;&#x2F;path&#x2F;to&#x2F;local&#x2F;repo&lt;&#x2F;localRepository&gt;</span><br><span class="line"># 配置阿里云镜像</span><br><span class="line">&lt;mirrors&gt;  </span><br><span class="line">&lt;mirror&gt;  </span><br><span class="line">&lt;id&gt;mirrorId&lt;&#x2F;id&gt;  </span><br><span class="line">&lt;mirrorOf&gt;repositoryId&lt;&#x2F;mirrorOf&gt;  </span><br><span class="line">&lt;name&gt;Human Readable Name for this Mirror.&lt;&#x2F;name&gt;  </span><br><span class="line">&lt;url&gt;http:&#x2F;&#x2F;my.repository.com&#x2F;repo&#x2F;path&lt;&#x2F;url&gt;  </span><br><span class="line">&lt;&#x2F;mirror&gt;  </span><br><span class="line">&lt;mirror&gt;  </span><br><span class="line">&lt;id&gt;alimaven&lt;&#x2F;id&gt;  </span><br><span class="line">&lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;  </span><br><span class="line">&lt;name&gt;aliyun maven&lt;&#x2F;name&gt;</span><br><span class="line">&lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;  </span><br><span class="line">&lt;&#x2F;mirror&gt;  </span><br><span class="line">&lt;&#x2F;mirrors&gt; </span><br><span class="line"># Idea中配置Maven</span><br><span class="line">在setting中搜索maven</span><br><span class="line">配置Maven home directory:</span><br><span class="line">配置MAVEN_OPTS</span><br><span class="line">配置setting文件</span><br></pre></td></tr></table></figure><h1 id="Maven命令"><a href="#Maven命令" class="headerlink" title="Maven命令"></a>Maven命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mvn clean 清除项目的生成结果</span><br><span class="line">mvn package 打包项目生成jar&#x2F;war文件</span><br><span class="line">mvn install 安装jar至本地库</span><br><span class="line">mvn compile 编译源代码</span><br><span class="line">mvn deploy 上传至私服</span><br><span class="line">mvn jar:jar 只打jar包</span><br><span class="line">mvn clean  install package -Dmaven.test.skip&#x3D;true #清理之前项目生成结果并构建然后将依赖包安装到本地仓库跳过测试</span><br><span class="line">mvn clean deploy package  -Dmaven.test.skip&#x3D;true #构建并将依赖放入私有仓库</span><br><span class="line">mvn --settings &#x2F;data&#x2F;settings.xml clean package -Dmaven.test.skip&#x3D;true #指定maven配置文件构建</span><br><span class="line">mvn install:install-file -DgroupId&#x3D;com.zebra -DartifactId&#x3D;ZSDK_CARD_API -Dversion&#x3D;v2.12.3782 -Dpackaging&#x3D;jar -Dfile&#x3D;E:\perslib\ZSDK_CARD_API.jar #安装特定jar包到仓库</span><br></pre></td></tr></table></figure><h1 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SCALA_HOME : D:\Program Files\scala</span><br><span class="line">Path ：%SCALA_HOME%\bin\</span><br><span class="line">Idea安装直接安装Scala插件</span><br></pre></td></tr></table></figure><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOMED:\software\hadoop2.6</span><br><span class="line">Path;%HADOOP_HOME%\bin</span><br></pre></td></tr></table></figure><h1 id="IDEA使用快捷键"><a href="#IDEA使用快捷键" class="headerlink" title="IDEA使用快捷键"></a>IDEA使用快捷键</h1><ul><li>代码自动提示<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.要保证File--&gt;Power On Save Mode是关闭状态</span><br><span class="line">2.File–&gt;Settings–&gt;Editor–&gt;General–&gt;Code Completion-&gt;Match case取消选中</span><br><span class="line">3.重启解决 问题</span><br></pre></td></tr></table></figure></li><li>打印-sout</li><li>局部变量-.var</li><li>成员变量-.field</li><li>格式化字符串-.format</li><li>判断非空-.nn,.null,.notnull</li><li>取反-.not</li><li>遍历-.for,.fori,.forr</li><li>返回值-.return</li><li>同步锁-.synchronized</li><li>Lambda表达式-.lamda</li></ul><h1 id="IDEA开发需要装的插件"><a href="#IDEA开发需要装的插件" class="headerlink" title="IDEA开发需要装的插件"></a>IDEA开发需要装的插件</h1><ul><li>Scala</li><li>Lombok(不用写实体类的get、set方法)</li></ul><h1 id="IDEA激活方法"><a href="#IDEA激活方法" class="headerlink" title="IDEA激活方法"></a>IDEA激活方法</h1><ul><li>Help–&gt;Edit Custom VM Option –&gt;添加一下内容<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA 2019.2.4\punk\jetbrains-agent.jar</span><br></pre></td></tr></table></figure></li><li>Help -&gt; Register–&gt;填入验证码<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A82DEE284F-eyJsaWNlbnNlSWQiOiJBODJERUUyODRGIiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiJVbmxpbWl0ZWQgbGljZW5zZSB0aWxsIGVuZCBvZiB0aGUgY2VudHVyeS4iLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJNIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiODkwNzA3MC8wIiwiZ3JhY2VQZXJpb2REYXlzIjowLCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-5epo90Xs7KIIBb8ckoxnB&#x2F;AZQ8Ev7rFrNqwFhBAsQYsQyhvqf1FcYdmlecFWJBHSWZU9b41kvsN4bwAHT5PiznOTmfvGv1MuOzMO0VOXZlc+edepemgpt+t3GUHvfGtzWFYeKeyCk+CLA9BqUzHRTgl2uBoIMNqh5izlDmejIwUHLl39QOyzHiTYNehnVN7GW5+QUeimTr&#x2F;koVUgK8xofu59Tv8rcdiwIXwTo71LcU2z2P+T3R81fwKkt34evy7kRch4NIQUQUno&#x2F;&#x2F;Pl3V0rInm3B2oFq9YBygPUdBUbdH&#x2F;KHROyohZRD8SaZJO6kUT0BNvtDPKF4mCT1saWM38jkw&#x3D;&#x3D;-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG&#x2F;PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg&#x2F;nYV31HLF7fJUAplI&#x2F;1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl&#x2F;GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4&#x2F;G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd&#x2F;GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt&#x2F;wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59&#x2F;THOT7NJQhr6AyLkhhJCdkzE2cob&#x2F;KouVp4ivV7Q3Fc6HX7eepHAAF&#x2F;DpxwgOrg9smX6coXLgfp0b1RU2u&#x2F;tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB&#x2F;40BjpMUrDRCeKuiBahC0DCoU&#x2F;4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV&#x2F;g&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3AGXEJXFK9-eyJsaWNlbnNlSWQiOiIzQUdYRUpYRks5IiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkFDIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJHTyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJETSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSUzAiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkQiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUk0iLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREIiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9XSwiaGFzaCI6IjEyNzk2ODc3LzAiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0&#x3D;-WGTHs6XpDhr+uumvbwQPOdlxWnQwgnGaL4eRnlpGKApEEkJyYvNEuPWBSrQkPmVpim&#x2F;8Sab6HV04Dw3IzkJT0yTc29sPEXBf69+7y6Jv718FaJu4MWfsAk&#x2F;ZGtNIUOczUQ0iGKKnSSsfQ&#x2F;3UoMv0q&#x2F;yJcfvj+me5Zd&#x2F;gfaisCCMUaGjB&#x2F;lWIPpEPzblDtVJbRexB1MALrLCEoDv3ujcPAZ7xWb54DiZwjYhQvQ+CvpNNF2jeTku7lbm5v+BoDsdeRq7YBt9ANLUKPr2DahcaZ4gctpHZXhG96IyKx232jYq9jQrFDbQMtVr3E+GsCekMEWSD&#x2F;&#x2F;dLT+HuZdc1sAIYrw&#x3D;&#x3D;-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG&#x2F;PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg&#x2F;nYV31HLF7fJUAplI&#x2F;1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl&#x2F;GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4&#x2F;G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd&#x2F;GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt&#x2F;wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59&#x2F;THOT7NJQhr6AyLkhhJCdkzE2cob&#x2F;KouVp4ivV7Q3Fc6HX7eepHAAF&#x2F;DpxwgOrg9smX6coXLgfp0b1RU2u&#x2F;tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB&#x2F;40BjpMUrDRCeKuiBahC0DCoU&#x2F;4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV&#x2F;g&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNBB2QUUR1-eyJsaWNlbnNlSWQiOiJLTkJCMlFVVVIxIiwibGljZW5zZWVOYW1lIjoiZ2hib2tlIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiQUMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRFBOIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRNIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJTMCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSTSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJXUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSU1UiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiMTI3OTY4NzcvMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ&#x3D;&#x3D;-1iV7BA&#x2F;baNqv0Q5yUnAphUmh66QhkDRX+qPL09ICuEicBqiPOBxmVLLCVUpkxhrNyfmOtat2LcHwcX&#x2F;NHkYXdoW+6aS0S388xe1PV2oodiPBhFlEaOac42UQLgP4EidfGQSvKwC9tR1zL5b2CJPQKZ7iiHh&#x2F;iKBQxP6OBMUP1T7j3Fe1rlxfYPc92HRZf6cO+C0+buJP5ERZkyIn5ZrVM4TEnWrRHbpL8SVNq4yqfc+NwoRzRSNC++81VDS3AXv9c91YeZJz6JXO7AokIk54wltr42FLNuKbozvB&#x2F;HCxV9PA5vIiM+kZY1K0w5ytgxEYKqA87adA7R5xL&#x2F;crpaMxHQ&#x3D;&#x3D;-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG&#x2F;PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg&#x2F;nYV31HLF7fJUAplI&#x2F;1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl&#x2F;GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4&#x2F;G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd&#x2F;GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt&#x2F;wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59&#x2F;THOT7NJQhr6AyLkhhJCdkzE2cob&#x2F;KouVp4ivV7Q3Fc6HX7eepHAAF&#x2F;DpxwgOrg9smX6coXLgfp0b1RU2u&#x2F;tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB&#x2F;40BjpMUrDRCeKuiBahC0DCoU&#x2F;4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV&#x2F;g&#x3D;&#x3D;</span><br></pre></td></tr></table></figure></li><li>然后重启就可以使用了</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业用自建Git服务器</title>
      <link href="/2019/12/01/%E4%BC%81%E4%B8%9A%E7%94%A8%E8%87%AA%E5%BB%BAGit%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <url>/2019/12/01/%E4%BC%81%E4%B8%9A%E7%94%A8%E8%87%AA%E5%BB%BAGit%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Centos7-git安装"><a href="#Centos7-git安装" class="headerlink" title="Centos7 git安装"></a>Centos7 git安装</h1><h3 id="一-安装"><a href="#一-安装" class="headerlink" title="一.安装"></a>一.安装</h3><ul><li>检查是否安装过:rpm -qa | grep git  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果安装过，卸载</span></span><br><span class="line">rpm -e --nodeps git</span><br></pre></td></tr></table></figure></li><li>安装git:yum install git</li><li>git –version</li></ul><h3 id="二-配置ssh-key"><a href="#二-配置ssh-key" class="headerlink" title="二.配置ssh key"></a>二.配置ssh key</h3><ul><li>初始化ssk-key，回车  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C "hufei1459@163.com"</span><br></pre></td></tr></table></figure></li><li>eval “$(ssh-agent -s)”</li><li>ssh-add ~/.ssh/id_rsa<h3 id="在网站添加你的ssk-key"><a href="#在网站添加你的ssk-key" class="headerlink" title="在网站添加你的ssk-key"></a>在网站添加你的ssk-key</h3></li><li>/root/.ssh/id_rsa.pub<h3 id="测试连接"><a href="#测试连接" class="headerlink" title="测试连接"></a>测试连接</h3></li><li>ssh -T <a href="mailto:git@github.com">git@github.com</a></li></ul><hr><h1 id="使用Gogs搭建git服务器"><a href="#使用Gogs搭建git服务器" class="headerlink" title="使用Gogs搭建git服务器"></a>使用Gogs搭建git服务器</h1><h2 id="1-配置Gogs所需的环境"><a href="#1-配置Gogs所需的环境" class="headerlink" title="1.配置Gogs所需的环境"></a>1.配置Gogs所需的环境</h2><ul><li>安装nginx<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nginx</span><br></pre></td></tr></table></figure></li><li>安装git<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure></li><li>安装MySQL<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install mysql-server # 安装mysql</span><br><span class="line">mysql -u root -p # 连接数据库</span><br><span class="line">SET GLOBAL storage_engine = 'InnoDB';  # 设置数据库模式为InnoDB</span><br><span class="line">CREATE DATABASE gogs CHARACTER SET utf8 COLLATE utf8_bin; # 创建数据库名字为gogs</span><br><span class="line">GRANT ALL PRIVILEGES ON gogs.* TO ‘root’@‘localhost’ IDENTIFIED BY 'YourPassword'; # 给数据库gogs赋权限</span><br><span class="line">FLUSH PRIVILEGES;  # 刷新</span><br><span class="line">QUIT； # 退出</span><br></pre></td></tr></table></figure></li><li>为Gogs创建单独的用户<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser git  # 创建用户git</span><br><span class="line">su git # 切换到git用户</span><br><span class="line">cd ~  # 切换到home目录</span><br><span class="line">wget https://dl.gogs.io/0.11.4/linux_amd64.zip # 下载gogs</span><br><span class="line">unzip linux_amd64.zip # 解压</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-配置与运行Gogs"><a href="#2-配置与运行Gogs" class="headerlink" title="2.配置与运行Gogs"></a>2.配置与运行Gogs</h2><ul><li>修改Gogs service配置文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/git/gogs/scripts/init/centos/gogs</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PATH=/sbin:/usr/sbin:/bin:/usr/bin</span><br><span class="line">DESC="Go Git Service"</span><br><span class="line">NAME=gogs</span><br><span class="line">SERVICEVERBOSE=yes</span><br><span class="line">PIDFILE=/var/run/$NAME.pid</span><br><span class="line">SCRIPTNAME=/etc/init.d/$NAME</span><br><span class="line">WORKINGDIR=/home/git/gogs #这个根据自己的目录修改</span><br><span class="line">DAEMON=$WORKINGDIR/$NAME</span><br><span class="line">DAEMON_ARGS="web"</span><br><span class="line">USER=git  #如果运行gogs不是用的这个用户，修改对应用户</span><br></pre></td></tr></table></figure></li><li>切换到root账户然后复制到/etc/init.d/<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /home/git/gogs/scripts/init/centos/gogs /etc/init.d/</span><br></pre></td></tr></table></figure></li><li>增加执行权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod +x /etc/init.d/gogs</span><br></pre></td></tr></table></figure></li><li>复制service<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /home/git/gogs/scripts/systemd/gogs.service /etc/systemd/system/</span><br></pre></td></tr></table></figure></li><li>启动Gogs<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service gogs start</span><br></pre></td></tr></table></figure></li></ul><h2 id="3-浏览器配置gogs"><a href="#3-浏览器配置gogs" class="headerlink" title="3.浏览器配置gogs"></a>3.浏览器配置gogs</h2><ul><li>打开浏览器3000端口<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://*******:3000/install # 星号部分换成ip地址</span><br></pre></td></tr></table></figure></li><li>配置gogs.相关资料：<a href="https://gogs.io/docs/advanced/configuration_cheat_sheet" target="_blank" rel="noopener" title="gogs配置手册">gogs配置手册</a></li><li>gogs配置文件：/home/git/gogs/custom/conf/app.ini</li></ul><h2 id="4-nginx-反向代理"><a href="#4-nginx-反向代理" class="headerlink" title="4.nginx 反向代理"></a>4.nginx 反向代理</h2><ul><li>创建相应的配置文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/nginx/sites-enabled/gogs.conf</span><br></pre></td></tr></table></figure></li><li>添加<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name  code.chinahufei.com;</span><br><span class="line">        location / &#123;</span><br><span class="line">                proxy_pass http://127.0.0.1:3000/;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>如此，注册创建账号，登录即可。</li></ul><h3 id="如何在局域网搭建git服务器"><a href="#如何在局域网搭建git服务器" class="headerlink" title="如何在局域网搭建git服务器"></a>如何在局域网搭建git服务器</h3><ul><li><a href="https://www.cnblogs.com/hujunzheng/p/4970411.html" target="_blank" rel="noopener" title="https://www.cnblogs.com/hujunzheng/p/4970411.html">https://www.cnblogs.com/hujunzheng/p/4970411.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据Linux重要命令</title>
      <link href="/2019/11/29/%E5%A4%A7%E6%95%B0%E6%8D%AELinux%E9%87%8D%E8%A6%81%E5%91%BD%E4%BB%A4/"/>
      <url>/2019/11/29/%E5%A4%A7%E6%95%B0%E6%8D%AELinux%E9%87%8D%E8%A6%81%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-Basic-Command"><a href="#Linux-Basic-Command" class="headerlink" title="Linux Basic Command"></a>Linux Basic Command</h1><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul><li><p>1.解压到特定目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf file.tar.gz -C &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line">tar -zcvf afterName.tar beforeName</span><br></pre></td></tr></table></figure></li><li><p>2.更改目录所属权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chown username fileName</span><br><span class="line">sudo chgrp userName fileName</span><br></pre></td></tr></table></figure></li><li><p>3.切换用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su - mysqladmin</span><br><span class="line">usermod -g groupName userName</span><br></pre></td></tr></table></figure></li><li><p>4.发送和下载文件到特定机器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r &#x2F;root&#x2F;demo root@123.25.23.108 &#x2F;root&#x2F;opt</span><br><span class="line">scp -P 22 -r root@123.25.23.108:&#x2F;home&#x2F;opt&#x2F; &#x2F;home&#x2F;my&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>5.登录特定机器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 root@ip192.168.0.3</span><br></pre></td></tr></table></figure></li><li><p>6.禁用IPv6地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &#39;net.ipv6.conf.all.disable_ipv6 &#x3D; 1&#39; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">sudo sysctl -p &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"># file: &#x2F;etc&#x2F;hosts</span><br><span class="line">#::1     localhost ip6-localhost ip6-loopback</span><br></pre></td></tr></table></figure></li><li><p>7.查看文件内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tail -f access.log     # 实时查看文件</span><br><span class="line">tail -200f access.log  # 查看最后200行</span><br></pre></td></tr></table></figure></li><li><p>8.创建软连接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s rootLocation targetLocation</span><br></pre></td></tr></table></figure></li><li><p>9.搜索文本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find &#x2F;tmp -size +4M -size -5M &#39;*.log&#39; #在tmp目录下查找大于4M小于5M的日志文件</span><br><span class="line">grep -n &#39;.c.&#39; test.txt #在test.txt中搜索包含c的文本</span><br></pre></td></tr></table></figure></li><li><p>10.端口和进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep nginx#查看进程pid</span><br><span class="line">netstat -nap | grep 进程pid#通过pid查看端口</span><br><span class="line">netstat -nap | grep 端口号#通过端口查看进程</span><br><span class="line">lsof -i:端口号#通过端口查看进程</span><br><span class="line">telnet 10.20.66.37 8090         # ping端口</span><br><span class="line">ping 192.168.0.2                # ping ip</span><br></pre></td></tr></table></figure></li><li><p>11.进程相关</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">last&#x2F;lastlog: 查看用户最近登录情况</span><br><span class="line">df: 查看硬盘使用情况</span><br><span class="line">du: 查看文件大小</span><br><span class="line">free: 查看内存使用情况</span><br><span class="line">&#x2F;proc: 查看文件系统</span><br><span class="line">ls &#x2F;var&#x2F;log&#x2F;: 查看日志</span><br><span class="line">tail &#x2F;var&#x2F;log&#x2F;messages: 查看系统报错日志</span><br><span class="line">top: 查看进程</span><br><span class="line">kill 1234&#x2F;kill -9 4333: 结束进程</span><br></pre></td></tr></table></figure></li><li><p>12.上传下载文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install lrzsz -y # 安装</span><br><span class="line">sz filename #下载文件到本地</span><br><span class="line">rz 上传文件</span><br></pre></td></tr></table></figure></li></ul><h3 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">1.通用</span><br><span class="line">/sbin/iptables -I INPUT -p tcp --dport 27017 -j ACCEPT  </span><br><span class="line">/etc/rc.d/init.d/iptables save</span><br><span class="line">2.centos7 临时操作</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">注：如果centos7下需要使用iptables</span><br><span class="line">yum install iptables-services,systemctl enable iptables,systemctl start iptables</span><br><span class="line">3.centos6 临时操作</span><br><span class="line">service iptables stop/start/status/restart</span><br><span class="line">4.查看某端口的防火墙状态</span><br><span class="line">firewall-cmd --query-port=666/tcp</span><br><span class="line">5.查看防火墙开放的端口</span><br><span class="line">iptables -L -n</span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他参考</span></span><br><span class="line">1. 查看已打开的端口 # netstat -anp</span><br><span class="line">2. 查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp</span><br><span class="line">若此提示 FirewallD is not running</span><br><span class="line">表示为不可知的防火墙 需要查看状态并开启防火墙</span><br><span class="line"></span><br><span class="line">3. 查看防火墙状态 # systemctl status firewalld</span><br><span class="line">running 状态即防火墙已经开启</span><br><span class="line">dead 状态即防火墙未开启</span><br><span class="line">4. 开启防火墙，# systemctl start firewalld 没有任何提示即开启成功</span><br><span class="line">5. 开启防火墙 # service firewalld start</span><br><span class="line">关闭防火墙 # systemctl stop firewalld</span><br><span class="line">centos7.3 上述方式可能无法开启，可以先#systemctl unmask firewalld.service 然后 # systemctl start firewalld.service</span><br><span class="line"></span><br><span class="line">6. 查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp 提示no表示未开</span><br><span class="line">7. 开永久端口号 firewall-cmd --add-port=666/tcp --permanent 提示 success 表示成功</span><br><span class="line">8. 重新载入配置 # firewall-cmd --reload 比如添加规则之后，需要执行此命令</span><br><span class="line">9. 再次查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp 提示yes表示成功</span><br><span class="line">10. 若移除端口 # firewall-cmd --permanent --remove-port=666/tcp</span><br><span class="line"></span><br><span class="line">11. 修改iptables 有些版本需要安装iptables-services # yum install iptables-services 然后修改进目录 /etc/sysconfig/iptables 修改内容</span><br></pre></td></tr></table></figure><h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1.搜索进程</span><br><span class="line">ps -ef | grep java</span><br><span class="line">2.根据用户过滤进程</span><br><span class="line">ps -u root</span><br><span class="line">3.根据cpu来筛选进程</span><br><span class="line">ps -aux --sort -pcpu | less</span><br><span class="line">4.根据内存来筛选 进程</span><br><span class="line">ps -aux --sort -pmem | less</span><br><span class="line">ps -aux --sort -pcpu,+pmem | head -n 10</span><br><span class="line">5.通过进程名和PID过滤</span><br><span class="line">ps -C java</span><br><span class="line">6.根据线程过滤</span><br><span class="line">ps -L 1213</span><br><span class="line">7.查看详细信息</span><br><span class="line">ps -f -C java</span><br><span class="line">8.显示为树形</span><br><span class="line">pstree</span><br><span class="line">9.显示安全信息(登录服务器记录)</span><br><span class="line">ps -eo pid,user,args</span><br><span class="line">10.实时监控进程状态</span><br><span class="line">watch -n 1 ‘ps -aux --sort -pmem, -pcpu’</span><br><span class="line">watch -n 1 ‘ps -aux --sort -pmem, -pcpu | head 20’</span><br><span class="line">11.查看前10个进程</span><br><span class="line">ps -aux |head -n 10</span><br><span class="line">12.查看后10个进程</span><br><span class="line">ps -aux |tail -n 10</span><br><span class="line">13.查看内存使用的前10个进程</span><br><span class="line">ps -aux |sort -nk3|head -n 10</span><br></pre></td></tr></table></figure><h3 id="top"><a href="#top" class="headerlink" title="top"></a>top</h3><h4 id="前五行是统计信息区"><a href="#前五行是统计信息区" class="headerlink" title="前五行是统计信息区"></a>前五行是统计信息区</h4><ul><li>第一行(任务队列信息)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">01:06:48 : 当前时间</span><br><span class="line">up 1:22 : 系统运行时间，格式为时:分</span><br><span class="line">1 user : 当前登录用户数</span><br><span class="line">load average: 0.06, 0.60, 0.48 : 系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。</span><br></pre></td></tr></table></figure></li><li>第二、三行(进程和CPU)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Tasks: 29 total  : 总进程数</span><br><span class="line">1 running        : 正在运行的进程数</span><br><span class="line">28 sleeping      : 睡眠的进程数</span><br><span class="line">0 stopped        : 停止的进程数</span><br><span class="line">0 zombie         : 僵尸进程数</span><br><span class="line">Cpu(s): 0.3% us  : 用户空间占用CPU百分比</span><br><span class="line">1.0% sy         : 内核空间占用CPU百分比</span><br><span class="line">0.0% ni         : 用户进程空间内改变过优先级的进程占用CPU百分比</span><br><span class="line">98.7% id         : 空闲CPU百分比</span><br><span class="line">0.0% wa         : 等待输入输出的CPU时间百分比</span><br></pre></td></tr></table></figure></li><li>第四、五行(内存信息)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Mem: 191272k total :物理内存总量</span><br><span class="line">173656k used   :    使用的物理内存总量</span><br><span class="line">17616k free       :    空闲内存总量</span><br><span class="line">22052k buffers   :    用作内核缓存的内存量</span><br><span class="line">Swap: 192772k total:交换区总量</span><br><span class="line">0k used           :    使用的交换区总量</span><br><span class="line">192772k free   :    空闲交换区总量</span><br><span class="line">123988k cached   :    缓冲的交换区总量。</span><br><span class="line">内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，</span><br><span class="line">该数值即为这些内容已存在于内存中的交换区的大小。</span><br><span class="line">相应的内存再次被换出时可不必再对交换区写入。</span><br></pre></td></tr></table></figure><h4 id="列表是进程信息区"><a href="#列表是进程信息区" class="headerlink" title="列表是进程信息区"></a>列表是进程信息区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PID    :进程id</span><br><span class="line">PPID:父进程id</span><br><span class="line">RUSER:Real user name</span><br><span class="line">UID    :进程所有者的用户id</span><br><span class="line">USER:进程所有者的用户名</span><br><span class="line">GROUP:进程所有者的组名</span><br><span class="line">TTY    :启动进程的终端名。不是从终端启动的进程则显示为</span><br><span class="line">PR    :优先级</span><br><span class="line">NI    :nice值。负值表示高优先级，正值表示低优先级</span><br><span class="line">P    :最后使用的CPU，仅在多CPU环境下有意义</span><br><span class="line">%CPU:上次更新到现在的CPU时间占用百分比</span><br><span class="line">TIME:进程使用的CPU时间总计，单位秒</span><br><span class="line">TIME+:进程使用的CPU时间总计，单位1&#x2F;100秒</span><br><span class="line">%MEM:进程使用的物理内存百分比</span><br><span class="line">VIRT:进程使用的虚拟内存总量，单位kb。VIRT&#x3D;SWAP+RES</span><br><span class="line">SWAP:进程使用的虚拟内存中，被换出的大小，单位kb。</span><br><span class="line">RES    :进程使用的、未被换出的物理内存大小，单位kb。RES&#x3D;CODE+DATA</span><br><span class="line">CODE:可执行代码占用的物理内存大小，单位kb</span><br><span class="line">DATA:可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb</span><br><span class="line">SHR    :共享内存大小，单位kb</span><br><span class="line">nFLT:页面错误次数</span><br><span class="line">nDRT:最后一次写入到现在，被修改过的页面数。</span><br><span class="line">S    :进程状态。D&#x3D;不可中断的睡眠状态 R&#x3D;运行 S&#x3D;睡眠 T&#x3D;跟踪&#x2F;停止 Z&#x3D;僵尸进程</span><br><span class="line">COMMAND:命令名&#x2F;命令行</span><br><span class="line">WCHAN:若该进程在睡眠，则显示睡眠中的系统函数名</span><br><span class="line">Flags:任务标志，参考 sched.h</span><br></pre></td></tr></table></figure></li></ul><h3 id="find"><a href="#find" class="headerlink" title="find"></a>find</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.查找当前目录以及子目录以.c结尾的文件</span><br><span class="line">find . -name &#39;*.c&#39;</span><br><span class="line">2.列出当前目录及其子目录中的所有一般文件</span><br><span class="line">find . -type f</span><br><span class="line">3.列出当前目录及其子目录下所有最近20天内更新过的文件</span><br><span class="line">find . -ctime -20</span><br><span class="line">4.查找&#x2F;var&#x2F;log目录中更改时间在7日以前的普通文件，并在删除之前询问它们</span><br><span class="line">find &#x2F;var&#x2F;log -type f -mtime +7 ok rm &#123;&#125; \</span><br><span class="line">5.查找当前目录中文件是644组合的文件列表</span><br><span class="line">find . -type f -perm 644 -exec ls -l &#123;&#125; \;</span><br><span class="line">6.查找系统中所有文件长度为0的为普通文件，并列出它们的完整路径</span><br><span class="line">find &#x2F; -type f –size 0 –exec ls –l &#123;&#125; \</span><br></pre></td></tr></table></figure><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1.查找包含match_pattern的所有行</span><br><span class="line">grep match_pattern file_name</span><br><span class="line">2.多个文件查找</span><br><span class="line">grep match_pattern file1 file2 file3</span><br><span class="line">3.输出除之外的所有行</span><br><span class="line">grep -v “match_pattern” file_name</span><br><span class="line">4.使用正则表达式</span><br><span class="line">grep -E &#39;[1-9]+&#39;</span><br><span class="line">5.只输出文件中匹配的部分</span><br><span class="line">echo this is a test line. | grep -o -E &#39;[a-z]+\.&#39;</span><br><span class="line">6.统计文本中包含匹配字符串的行数</span><br><span class="line">grep -c “text” file_name</span><br><span class="line">7.在多级目录中对文本进行递归搜索</span><br><span class="line">grep “text” . -r -n</span><br></pre></td></tr></table></figure><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><ul><li>动作说明: a-新增，c-取代，d-删除，i-插入，p-打印，s-取代</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">1.添加-在testfile文件的第四行后添加一行，并将结果输出到标准输出</span><br><span class="line">sed -e 4a\newLine testfile</span><br><span class="line">2.删除-将&#x2F;etc&#x2F;passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;2,5d&#39;</span><br><span class="line">3.删除第 3 到最后一行</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;3,$d&#39;</span><br><span class="line">4.在第二行后(亦即是加在第三行)加上『drink tea?』字样</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;2a drink tea&#39;</span><br><span class="line">5.在第二行前</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;2i drink tea&#39;</span><br><span class="line">6.要增加两行以上，在第二行后面加入两行字，例如 Drink tea or ..... 与 drink beer?</span><br><span class="line"> nl &#x2F;etc&#x2F;passwd | sed &#39;2a Drink tea or ......\</span><br><span class="line">&gt; drink beer ?&#39;</span><br><span class="line">7.将第2-5行的内容取代成为『No 2-5 number』</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;2,5c No 2-5 number&#39;</span><br><span class="line">8.仅列出 &#x2F;etc&#x2F;passwd 文件内的第 5-7 行</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed -n &#39;5,7p&#39;</span><br><span class="line">9.搜索 &#x2F;etc&#x2F;passwd有root关键字的行</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed &#39;&#x2F;root&#x2F;p&#39;</span><br><span class="line">10.删除&#x2F;etc&#x2F;passwd所有包含root的行，其他行输出</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed  &#39;&#x2F;root&#x2F;d&#39;</span><br><span class="line">11.搜索&#x2F;etc&#x2F;passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed -n &#39;&#x2F;root&#x2F;&#123;s&#x2F;bash&#x2F;blueshell&#x2F;;p;q&#125;&#39; </span><br><span class="line">12.将 IP 前面的部分予以删除</span><br><span class="line">&#x2F;sbin&#x2F;ifconfig eth0 | grep &#39;inet addr&#39; | sed &#39;s&#x2F;^.*addr:&#x2F;&#x2F;g&#39;</span><br><span class="line">13.将 IP 后面的部分予以删除</span><br><span class="line">&#x2F;sbin&#x2F;ifconfig eth0 | grep &#39;inet addr&#39; | sed &#39;s&#x2F;^.*addr:&#x2F;&#x2F;g&#39; | sed &#39;s&#x2F;Bcast.*$&#x2F;&#x2F;g&#39;</span><br><span class="line">14.一条sed命令，删除&#x2F;etc&#x2F;passwd第三行到末尾的数据，并把bash替换为blueshell</span><br><span class="line">nl &#x2F;etc&#x2F;passwd | sed -e &#39;3,$d&#39; -e &#39;s&#x2F;bash&#x2F;blueshell&#x2F;&#39;</span><br><span class="line">15.利用 sed 将 regular_express.txt 内每一行结尾若为 . 则换成 !</span><br><span class="line">sed -i &#39;s&#x2F;\.$&#x2F;\!&#x2F;g&#39; regular_express.txt</span><br></pre></td></tr></table></figure><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">1.搜索&#x2F;etc&#x2F;passwd有root关键字的所有行</span><br><span class="line">awk  &#39;&#x2F;root&#x2F;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">2.搜索&#x2F;etc&#x2F;passwd有root关键字的所有行，并显示对应的shell</span><br><span class="line">awk -F: &#39;&#x2F;root&#x2F; &#123;print $7&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">3.统计&#x2F;etc&#x2F;passwd:文件名，每行的行号，每行的列数，对应的完整行内容</span><br><span class="line">awk -F: &#39;&#123;printf (&quot;filename:%10s, linenumber:%3s,column:%3s,content:%3f\n&quot;,FILENAME,NR,NF,$0)&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">4.打印&#x2F;etc&#x2F;passwd&#x2F;的第二行信息</span><br><span class="line">awk -F: &#39;NR&#x3D;&#x3D;2&#123;print &quot;filename: &quot;FILENAME, $0&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">5.指定特定的分隔符，查询第一列</span><br><span class="line">awk -F &quot;:&quot; &#39;&#123;print $1&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">6.指定特定的分隔符，查询最后一列</span><br><span class="line">awk -F &quot;:&quot; &#39;&#123;print $NF&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">7.指定特定的分隔符，查询倒数第二列</span><br><span class="line">awk -F &quot;:&quot; &#39;&#123;print $NF-1&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">8.获取第12到31行的第一列的信息</span><br><span class="line">awk -F &quot;:&quot;  &#39;&#123;if(NR&lt;31 &amp;&amp; NR &gt;12) print $1&#125;&#39; &#x2F;etc&#x2F;passwd</span><br><span class="line">9.查看最近登录最多的IP信息</span><br><span class="line">last | awk &#39;&#123;S[$3]++&#125; END&#123;for(a in S ) &#123;print S[a],a&#125;&#125;&#39; |uniq| sort -rh</span><br><span class="line">10.利用正则过滤多个空格</span><br><span class="line">ifconfig |grep eth* | awk -F &#39;[ ]+&#39; &#39;&#123;print $1&#125;&#39;&lt;br&gt;&lt;br&gt;</span><br><span class="line">10.统计某个文件夹下的大于100k文件的数量和总和</span><br><span class="line">ls -l|awk &#39;&#123;if($5&gt;100)&#123;count++; sum+&#x3D;$5&#125;&#125; &#123;print &quot;Count:&quot; count,&quot;Sum: &quot; sum&#125;&#39;</span><br><span class="line">11.统计显示&#x2F;etc&#x2F;passwd的账户</span><br><span class="line">awk -F: &#39;&#123;count++;&#125; END&#123;print count&#125;&#39; &#x2F;etc&#x2F;passwd        </span><br><span class="line">cat &#x2F;etc&#x2F;passwd|wc -l</span><br><span class="line">awk -F &#39;:&#39; &#39;BEGIN &#123;count&#x3D;0;&#125; &#123;name[count] &#x3D; $1;count++;&#125;; END&#123;for (i &#x3D; 0; i &lt; NR; i++) print i, name[i]&#125;&#39; &#x2F;etc&#x2F;passwd</span><br></pre></td></tr></table></figure><h3 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1.获取有多少个字符</span><br><span class="line">wc functest.sh -c</span><br><span class="line">2.使用&#39; &#39;进行分割，获取第一个参数</span><br><span class="line">wc functest.sh -c | cut -d &#39; &#39; -f 1</span><br><span class="line">3.将PATH变量取出， 我要找出第5个变量</span><br><span class="line">echo $PATH | cut -d &#39;:&#39; -f 5</span><br><span class="line">4.将PATH变量取出， 我要找出第3和5个变量</span><br><span class="line">echo $PATH | cut -d &#39;:&#39; -f 3,5</span><br><span class="line">5.将PATH变量取出， 我要找出第3到最后一个</span><br><span class="line">echo $PATH | cut -d &#39;:&#39; -f 3-</span><br><span class="line">6.将PATH变量取出， 我要找出第3到第5个</span><br><span class="line">echo $PATH | cut -d &#39;:&#39; -f 3-5</span><br><span class="line">7.只显示&#x2F;etc&#x2F;passwd的用户和shell</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | cut -d &#39;:&#39; -f 1,7</span><br></pre></td></tr></table></figure><h3 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1.对&#x2F;etc&#x2F;passwd 的账号进行排序</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort</span><br><span class="line">2.对&#x2F;etc&#x2F;passwd 按照第三列进行排序(默认安装字母顺序排序)</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort -t &#39;:&#39; -k 3</span><br><span class="line">3.对&#x2F;etc&#x2F;passwd 按照第三列进行排序（按照数字排序)</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort -t &#39;:&#39; -k 3n  # 升序</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort -t &#39;:&#39; -k 3nr # 倒序</span><br><span class="line">4.对&#x2F;etc&#x2F;passwd  先按照第六个域的第2个字符到第4个字符排序，再按照第一个域倒序</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort -t &#39;:&#39; -k 6.2,6.4 -k 1r</span><br><span class="line">5.对&#x2F;etc&#x2F;passwd 按照第3个域排序后去重</span><br><span class="line">cat &#x2F;etc&#x2F;passwd | sort -t &#39;:&#39; -k 3 -u</span><br></pre></td></tr></table></figure><h3 id="uniq"><a href="#uniq" class="headerlink" title="uniq"></a>uniq</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat word.txt | sort | uniq</span><br></pre></td></tr></table></figure><h3 id="wc"><a href="#wc" class="headerlink" title="wc"></a>wc</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.统计行数</span><br><span class="line">wc -l &#x2F;etc&#x2F;passwd</span><br><span class="line">2.统计单词书</span><br><span class="line">wc -w &#x2F;etc&#x2F;passwd</span><br><span class="line">3.统计字符数</span><br><span class="line">wc -m &#x2F;etc&#x2F;passwd</span><br></pre></td></tr></table></figure><h3 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h3><ul><li>curl参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1. -X --request    [GET|POST|PUT|DELETE|…]    使用指定的HTTP method 发出指定的request</span><br><span class="line">2. -H --header    “XX:XXX”    设定request的header</span><br><span class="line">curl -i -H &quot;Content-Type: application&#x2F;json&quot; http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br><span class="line">-i --include    显示response的header</span><br><span class="line">3. -d --data    “XX&#x3D;XXX”    设定HTTP parameters</span><br><span class="line">curl -i -X POST -d “param1&#x3D;value1&amp;m2&#x3D;value2”</span><br><span class="line">4. -v --verbose    输出比较多的信息</span><br><span class="line">5. -u --user    “XX:XXX”    使用者帐密</span><br><span class="line">curl -i --user username:password http:&#x2F;&#x2F;www.rest.com&#x2F;api&#x2F;foo&#39;</span><br><span class="line">6. -b --cookie    cookie文件路径   使用cookie</span><br><span class="line">curl -i --header &quot;Accept:application&#x2F;json&quot; -X GET -b ~&#x2F;cookie.txt http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br><span class="line">7.session认证</span><br><span class="line">curl -X GET &#39;http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1&#39; --header &#39;sessionid:1234567890987654321&#39;</span><br><span class="line">8. 文件上传</span><br><span class="line">curl -i -X POST -F &#39;file&#x3D;@&#x2F;User&#x2F;my_file.txt&#39; -F &#39;name&#x3D;file_name&#39;</span><br></pre></td></tr></table></figure></li><li>wget获取http资源<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  --post-data&#x3D;&quot;xx&#x3D;xxx&quot; http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br></pre></td></tr></table></figure></li><li>curl实例<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 发送 json格式</span><br><span class="line">curl -H &#39;content-type: application&#x2F;json&#39; -X POST -d &#39;&#123;&quot;name&quot;:&quot;shfbjsf&quot;&#125;&#39; http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br><span class="line">2. 发送json文件</span><br><span class="line">curl -X POST -H &#39;content-type: application&#x2F;json&#39;  -d @&#x2F;apps&#x2F;jsonfile.json http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br><span class="line">3. 发送xml</span><br><span class="line">curl -H &#39;content-type: application&#x2F;xml&#39; -X POST -d &#39;&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;name&gt;aaa&lt;&#x2F;name&gt;&#39; http:&#x2F;&#x2F;chinahufei.com&#x2F;api&#x2F;v1&#x2F;banner&#x2F;1</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux&amp;Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
